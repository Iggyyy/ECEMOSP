{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from counterfactuals.explainers import Fimap\n",
    "from counterfactuals.constraints import ValueMonotonicity, ValueNominal, Freeze\n",
    "from data import AdultData\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def reset_random_seeds(seed=42):\n",
    "   os.environ['PYTHONHASHSEED']=str(seed)\n",
    "   tf.random.set_seed(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from counterfactuals.explainers import Fimap\n",
    "from data import AdultData\n",
    "\n",
    "adult_data = AdultData('data/datasets/adult.csv')\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(adult_data.X_train, adult_data.y_train)\n",
    "predictions = rf.predict(adult_data.X_train)\n",
    "\n",
    "categorical_columns = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'native.country']\n",
    "freeze_columns = ['race', 'sex', 'native.country']\n",
    "\n",
    "constraints = [\n",
    "            ValueNominal(columns=categorical_columns), \n",
    "            Freeze(columns=freeze_columns),\n",
    "            ValueMonotonicity(['age'], 'increasing')\n",
    "]\n",
    "\n",
    "fimap = Fimap(constraints=constraints)\n",
    "fimap.fit(adult_data.raw_X_train, predictions, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82      4533\n",
      "           1       0.50      0.76      0.60      1500\n",
      "\n",
      "    accuracy                           0.75      6033\n",
      "   macro avg       0.70      0.75      0.71      6033\n",
      "weighted avg       0.80      0.75      0.77      6033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "adult_data = AdultData('data/datasets/adult.csv')\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(adult_data.X_train, adult_data.y_train)\n",
    "print(classification_report(adult_data.y_test, rf.predict(adult_data.X_test)))\n",
    "model = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nadult_data = AdultData('data/datasets/adult.csv')\\nmodel = keras.models.load_model('models/model_adult')\\nmodel_predictions = model.predict(adult_data.X_train)\\nmodel_predictions[model_predictions > 0.5] = 1\\nmodel_predictions[model_predictions <= 0.5] = 0\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "adult_data = AdultData('data/datasets/adult.csv')\n",
    "model = keras.models.load_model('models/model_adult')\n",
    "model_predictions = model.predict(adult_data.X_train)\n",
    "model_predictions[model_predictions > 0.5] = 1\n",
    "model_predictions[model_predictions <= 0.5] = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = adult_data.raw_X_train, adult_data.raw_X_test, adult_data.raw_y_train, adult_data.raw_y_test\n",
    "model_predictions = rf.predict(adult_data.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(i, fimap):\n",
    "    original_class = model.predict(adult_data.X_train.iloc[i].to_frame().T)[0]\n",
    "    x = test_X.iloc[i]\n",
    "    cf = fimap.generate(x)\n",
    "    x[\"income\"] = original_class\n",
    "    surrogate_class = fimap._s_prediction\n",
    "    cf[\"income\"] = surrogate_class\n",
    "    return pd.concat([x.to_frame().T, cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training s\n",
      "Training loss (for one batch): 0.6841 \n",
      "Training accuracy 0.6051045\n",
      "Training loss (for one batch): 0.6702 \n",
      "Training accuracy 0.64175606\n",
      "Training loss (for one batch): 0.6458 \n",
      "Training accuracy 0.6636274\n",
      "Training loss (for one batch): 0.6093 \n",
      "Training accuracy 0.6792607\n",
      "Training loss (for one batch): 0.5655 \n",
      "Training accuracy 0.69105417\n",
      "Training loss (for one batch): 0.5295 \n",
      "Training accuracy 0.7002281\n",
      "Training loss (for one batch): 0.5109 \n",
      "Training accuracy 0.7076197\n",
      "Training loss (for one batch): 0.5029 \n",
      "Training accuracy 0.7138674\n",
      "Training loss (for one batch): 0.4954 \n",
      "Training accuracy 0.71941\n",
      "Training loss (for one batch): 0.4931 \n",
      "Training accuracy 0.72418344\n",
      "Training loss (for one batch): 0.4885 \n",
      "Training accuracy 0.7282899\n",
      "Training loss (for one batch): 0.4875 \n",
      "Training accuracy 0.7319031\n",
      "Training loss (for one batch): 0.4871 \n",
      "Training accuracy 0.7350088\n",
      "Training loss (for one batch): 0.4843 \n",
      "Training accuracy 0.73783785\n",
      "Training loss (for one batch): 0.4837 \n",
      "Training accuracy 0.74029714\n",
      "Training loss (for one batch): 0.4820 \n",
      "Training accuracy 0.742575\n",
      "Training loss (for one batch): 0.4798 \n",
      "Training accuracy 0.7446328\n",
      "Training loss (for one batch): 0.4808 \n",
      "Training accuracy 0.74649376\n",
      "Training loss (for one batch): 0.4804 \n",
      "Training accuracy 0.7482328\n",
      "Training loss (for one batch): 0.4775 \n",
      "Training accuracy 0.7498303\n",
      "Training loss (for one batch): 0.4766 \n",
      "Training accuracy 0.75133115\n",
      "Training loss (for one batch): 0.4758 \n",
      "Training accuracy 0.7526968\n",
      "Training loss (for one batch): 0.4748 \n",
      "Training accuracy 0.75398517\n",
      "Training loss (for one batch): 0.4723 \n",
      "Training accuracy 0.75521624\n",
      "Training loss (for one batch): 0.4702 \n",
      "Training accuracy 0.7563869\n",
      "Training loss (for one batch): 0.4710 \n",
      "Training accuracy 0.757496\n",
      "Training loss (for one batch): 0.4706 \n",
      "Training accuracy 0.7585085\n",
      "Training loss (for one batch): 0.4707 \n",
      "Training accuracy 0.7594461\n",
      "Training loss (for one batch): 0.4691 \n",
      "Training accuracy 0.76036584\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "fimap = Fimap(constraints=[ValueNominal(adult_data.categorical_columns)])\n",
    "fimap.fit(adult_data.raw_X_train, model_predictions, epochs=400)\n",
    "\n",
    "dfs = [compare(i, fimap) for i in range(200)]\n",
    "concat_df = pd.concat(dfs)\n",
    "concat_df.to_csv(\"results_nominal_constraints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueNominal(columns=['workclass', 'marital.status', 'occupation', 'race', 'sex'], values=[])\n",
      "Freeze(columns=['race', 'sex'])\n",
      "\n",
      "Training s\n",
      "Training loss (for one batch): 0.6849 \n",
      "Training accuracy 0.600897\n",
      "Training loss (for one batch): 0.6697 \n",
      "Training accuracy 0.65645\n",
      "Training loss (for one batch): 0.6434 \n",
      "Training accuracy 0.68066704\n",
      "Training loss (for one batch): 0.6026 \n",
      "Training accuracy 0.69414186\n",
      "Training loss (for one batch): 0.5555 \n",
      "Training accuracy 0.70330685\n",
      "Training loss (for one batch): 0.5231 \n",
      "Training accuracy 0.7106097\n",
      "Training loss (for one batch): 0.5099 \n",
      "Training accuracy 0.7168974\n",
      "Training loss (for one batch): 0.4979 \n",
      "Training accuracy 0.72246045\n",
      "Training loss (for one batch): 0.4905 \n",
      "Training accuracy 0.72732365\n",
      "Training loss (for one batch): 0.4888 \n",
      "Training accuracy 0.73159516\n",
      "Training loss (for one batch): 0.4864 \n",
      "Training accuracy 0.73532796\n",
      "Training loss (for one batch): 0.4857 \n",
      "Training accuracy 0.7386274\n",
      "Training loss (for one batch): 0.4820 \n",
      "Training accuracy 0.7415202\n",
      "Training loss (for one batch): 0.4797 \n",
      "Training accuracy 0.744093\n",
      "Training loss (for one batch): 0.4778 \n",
      "Training accuracy 0.74639666\n",
      "Training loss (for one batch): 0.4776 \n",
      "Training accuracy 0.7484898\n",
      "Training loss (for one batch): 0.4764 \n",
      "Training accuracy 0.7503383\n",
      "Training loss (for one batch): 0.4744 \n",
      "Training accuracy 0.7520488\n",
      "Training loss (for one batch): 0.4739 \n",
      "Training accuracy 0.7536157\n",
      "Training loss (for one batch): 0.4709 \n",
      "Training accuracy 0.7550874\n",
      "Training loss (for one batch): 0.4711 \n",
      "Training accuracy 0.75646734\n",
      "Training loss (for one batch): 0.4688 \n",
      "Training accuracy 0.7577349\n",
      "Training loss (for one batch): 0.4704 \n",
      "Training accuracy 0.75890994\n",
      "Training loss (for one batch): 0.4691 \n",
      "Training accuracy 0.760019\n",
      "Training loss (for one batch): 0.4668 \n",
      "Training accuracy 0.7610779\n",
      "Training loss (for one batch): 0.4680 \n",
      "Training accuracy 0.7621018\n",
      "Training loss (for one batch): 0.4663 \n",
      "Training accuracy 0.7630209\n",
      "Training loss (for one batch): 0.4647 \n",
      "Training accuracy 0.763932\n",
      "Training loss (for one batch): 0.4637 \n",
      "Training accuracy 0.7648011\n",
      "Training loss (for one batch): 0.4623 \n",
      "Training accuracy 0.7656316\n",
      "Training loss (for one batch): 0.4623 \n",
      "Training accuracy 0.7664512\n",
      "Training loss (for one batch): 0.4611 \n",
      "Training accuracy 0.76720136\n",
      "Training loss (for one batch): 0.4611 \n",
      "Training accuracy 0.7678845\n",
      "Training loss (for one batch): 0.4598 \n",
      "Training accuracy 0.76856935\n",
      "Training loss (for one batch): 0.4618 \n",
      "Training accuracy 0.76923406\n",
      "Training loss (for one batch): 0.4593 \n",
      "Training accuracy 0.7698521\n",
      "Training loss (for one batch): 0.4603 \n",
      "Training accuracy 0.7704447\n",
      "Training loss (for one batch): 0.4565 \n",
      "Training accuracy 0.7710543\n",
      "Training loss (for one batch): 0.4571 \n",
      "Training accuracy 0.7716408\n",
      "Training loss (for one batch): 0.4570 \n",
      "Training accuracy 0.77221125\n",
      "\n",
      "Training g\n",
      "Training loss (for one batch): 1.1605 \n",
      "Training accuracy 0.44092843\n",
      "Training loss (for one batch): 1.1724 \n",
      "Training accuracy 0.44016552\n",
      "Training loss (for one batch): 1.1414 \n",
      "Training accuracy 0.43969238\n",
      "Training loss (for one batch): 1.1516 \n",
      "Training accuracy 0.43928242\n",
      "Training loss (for one batch): 1.1014 \n",
      "Training accuracy 0.44007212\n",
      "Training loss (for one batch): 1.0810 \n",
      "Training accuracy 0.4416266\n",
      "Training loss (for one batch): 1.0062 \n",
      "Training accuracy 0.44444108\n",
      "Training loss (for one batch): 0.9927 \n",
      "Training accuracy 0.44894233\n",
      "Training loss (for one batch): 0.9693 \n",
      "Training accuracy 0.45352733\n",
      "Training loss (for one batch): 0.9539 \n",
      "Training accuracy 0.45826983\n",
      "Training loss (for one batch): 0.9434 \n",
      "Training accuracy 0.46305716\n",
      "Training loss (for one batch): 0.9370 \n",
      "Training accuracy 0.46756983\n",
      "Training loss (for one batch): 0.9210 \n",
      "Training accuracy 0.47207323\n",
      "Training loss (for one batch): 0.8940 \n",
      "Training accuracy 0.47673848\n",
      "Training loss (for one batch): 0.8795 \n",
      "Training accuracy 0.48208556\n",
      "Training loss (for one batch): 0.8469 \n",
      "Training accuracy 0.48827216\n",
      "Training loss (for one batch): 0.8328 \n",
      "Training accuracy 0.49497274\n",
      "Training loss (for one batch): 0.8190 \n",
      "Training accuracy 0.50141895\n",
      "Training loss (for one batch): 0.8260 \n",
      "Training accuracy 0.5071486\n",
      "Training loss (for one batch): 0.8257 \n",
      "Training accuracy 0.5123299\n",
      "Training loss (for one batch): 0.8174 \n",
      "Training accuracy 0.5171559\n",
      "Training loss (for one batch): 0.8038 \n",
      "Training accuracy 0.52162266\n",
      "Training loss (for one batch): 0.8153 \n",
      "Training accuracy 0.52567124\n",
      "Training loss (for one batch): 0.8160 \n",
      "Training accuracy 0.5294379\n",
      "Training loss (for one batch): 0.8237 \n",
      "Training accuracy 0.5329998\n",
      "Training loss (for one batch): 0.8118 \n",
      "Training accuracy 0.53623223\n",
      "Training loss (for one batch): 0.8127 \n",
      "Training accuracy 0.53932863\n",
      "Training loss (for one batch): 0.8069 \n",
      "Training accuracy 0.54222834\n",
      "Training loss (for one batch): 0.7977 \n",
      "Training accuracy 0.54495704\n",
      "Training loss (for one batch): 0.7972 \n",
      "Training accuracy 0.54751587\n",
      "Training loss (for one batch): 0.8067 \n",
      "Training accuracy 0.5498905\n",
      "Training loss (for one batch): 0.7941 \n",
      "Training accuracy 0.55217427\n",
      "Training loss (for one batch): 0.7928 \n",
      "Training accuracy 0.55435824\n",
      "Training loss (for one batch): 0.7918 \n",
      "Training accuracy 0.55638033\n",
      "Training loss (for one batch): 0.7904 \n",
      "Training accuracy 0.55839074\n",
      "Training loss (for one batch): 0.7945 \n",
      "Training accuracy 0.56027114\n",
      "Training loss (for one batch): 0.8028 \n",
      "Training accuracy 0.5620409\n",
      "Training loss (for one batch): 0.8099 \n",
      "Training accuracy 0.56368667\n",
      "Training loss (for one batch): 0.7966 \n",
      "Training accuracy 0.5653061\n",
      "Training loss (for one batch): 0.7998 \n",
      "Training accuracy 0.566812\n"
     ]
    }
   ],
   "source": [
    "for constraint in adult_data.constraints:\n",
    "    print(constraint)\n",
    "    \n",
    "fimap = Fimap(constraints=adult_data.constraints)\n",
    "fimap.fit(adult_data.raw_X_train, model_predictions, epochs=400)\n",
    "\n",
    "\n",
    "dfs = [compare(i, fimap) for i in range(200)]\n",
    "concat_df = pd.concat(dfs)\n",
    "concat_df.to_csv(\"results_normal_constraints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueNominal(columns=['workclass', 'marital.status', 'occupation', 'race', 'sex'], values=[])\n",
      "Freeze(columns=['race', 'sex'])\n",
      "\n",
      "Training s\n",
      "Training loss (for one batch): 0.6842 \n",
      "Training accuracy 0.5449325\n",
      "Training loss (for one batch): 0.6692 \n",
      "Training accuracy 0.59204733\n",
      "Training loss (for one batch): 0.6429 \n",
      "Training accuracy 0.62741506\n",
      "Training loss (for one batch): 0.6012 \n",
      "Training accuracy 0.6526979\n",
      "Training loss (for one batch): 0.5535 \n",
      "Training accuracy 0.67086923\n",
      "Training loss (for one batch): 0.5185 \n",
      "Training accuracy 0.68438596\n",
      "Training loss (for one batch): 0.5031 \n",
      "Training accuracy 0.69471055\n",
      "Training loss (for one batch): 0.4966 \n",
      "Training accuracy 0.7033498\n",
      "Training loss (for one batch): 0.4911 \n",
      "Training accuracy 0.71066624\n",
      "Training loss (for one batch): 0.4881 \n",
      "Training accuracy 0.7168504\n",
      "Training loss (for one batch): 0.4846 \n",
      "Training accuracy 0.72223467\n",
      "Training loss (for one batch): 0.4837 \n",
      "Training accuracy 0.7268163\n",
      "Training loss (for one batch): 0.4818 \n",
      "Training accuracy 0.7308645\n",
      "Training loss (for one batch): 0.4811 \n",
      "Training accuracy 0.7342955\n",
      "Training loss (for one batch): 0.4768 \n",
      "Training accuracy 0.7373479\n",
      "Training loss (for one batch): 0.4782 \n",
      "Training accuracy 0.7400742\n",
      "Training loss (for one batch): 0.4759 \n",
      "Training accuracy 0.7424983\n",
      "Training loss (for one batch): 0.4749 \n",
      "Training accuracy 0.7447234\n",
      "Training loss (for one batch): 0.4731 \n",
      "Training accuracy 0.7467304\n",
      "Training loss (for one batch): 0.4734 \n",
      "Training accuracy 0.74855745\n",
      "Training loss (for one batch): 0.4723 \n",
      "Training accuracy 0.7502796\n",
      "Training loss (for one batch): 0.4686 \n",
      "Training accuracy 0.75183725\n",
      "Training loss (for one batch): 0.4715 \n",
      "Training accuracy 0.7532868\n",
      "Training loss (for one batch): 0.4679 \n",
      "Training accuracy 0.75466335\n",
      "Training loss (for one batch): 0.4681 \n",
      "Training accuracy 0.7559582\n",
      "Training loss (for one batch): 0.4672 \n",
      "Training accuracy 0.7571332\n",
      "Training loss (for one batch): 0.4660 \n",
      "Training accuracy 0.75827354\n",
      "Training loss (for one batch): 0.4655 \n",
      "Training accuracy 0.759353\n",
      "Training loss (for one batch): 0.4632 \n",
      "Training accuracy 0.76037323\n",
      "Training loss (for one batch): 0.4659 \n",
      "Training accuracy 0.7613572\n",
      "Training loss (for one batch): 0.4632 \n",
      "Training accuracy 0.76228905\n",
      "Training loss (for one batch): 0.4617 \n",
      "Training accuracy 0.76318026\n",
      "Training loss (for one batch): 0.4630 \n",
      "Training accuracy 0.7640239\n",
      "Training loss (for one batch): 0.4602 \n",
      "Training accuracy 0.7648272\n",
      "Training loss (for one batch): 0.4616 \n",
      "Training accuracy 0.76562184\n",
      "Training loss (for one batch): 0.4597 \n",
      "Training accuracy 0.76634455\n",
      "Training loss (for one batch): 0.4613 \n",
      "Training accuracy 0.76703024\n",
      "Training loss (for one batch): 0.4585 \n",
      "Training accuracy 0.767709\n",
      "Training loss (for one batch): 0.4612 \n",
      "Training accuracy 0.7683556\n",
      "Training loss (for one batch): 0.4581 \n",
      "Training accuracy 0.7689724\n",
      "\n",
      "Training g\n",
      "Training loss (for one batch): 1.1675 \n",
      "Training accuracy 0.44592196\n",
      "Training loss (for one batch): 1.1536 \n",
      "Training accuracy 0.44568616\n",
      "Training loss (for one batch): 1.1496 \n",
      "Training accuracy 0.4456137\n",
      "Training loss (for one batch): 1.1146 \n",
      "Training accuracy 0.44539717\n",
      "Training loss (for one batch): 1.1311 \n",
      "Training accuracy 0.44610876\n",
      "Training loss (for one batch): 1.0685 \n",
      "Training accuracy 0.44727206\n",
      "Training loss (for one batch): 1.0236 \n",
      "Training accuracy 0.44984016\n",
      "Training loss (for one batch): 1.0057 \n",
      "Training accuracy 0.45401332\n",
      "Training loss (for one batch): 0.9774 \n",
      "Training accuracy 0.45914865\n",
      "Training loss (for one batch): 0.9592 \n",
      "Training accuracy 0.46436563\n",
      "Training loss (for one batch): 0.9553 \n",
      "Training accuracy 0.46959582\n",
      "Training loss (for one batch): 0.9541 \n",
      "Training accuracy 0.4742086\n",
      "Training loss (for one batch): 0.9494 \n",
      "Training accuracy 0.4783685\n",
      "Training loss (for one batch): 0.9346 \n",
      "Training accuracy 0.4823714\n",
      "Training loss (for one batch): 0.9156 \n",
      "Training accuracy 0.48628813\n",
      "Training loss (for one batch): 0.8925 \n",
      "Training accuracy 0.49058744\n",
      "Training loss (for one batch): 0.8884 \n",
      "Training accuracy 0.49528173\n",
      "Training loss (for one batch): 0.8858 \n",
      "Training accuracy 0.5001464\n",
      "Training loss (for one batch): 0.8795 \n",
      "Training accuracy 0.50495994\n",
      "Training loss (for one batch): 0.8752 \n",
      "Training accuracy 0.5094757\n",
      "Training loss (for one batch): 0.8631 \n",
      "Training accuracy 0.5135076\n",
      "Training loss (for one batch): 0.8655 \n",
      "Training accuracy 0.51716083\n",
      "Training loss (for one batch): 0.8606 \n",
      "Training accuracy 0.5207207\n",
      "Training loss (for one batch): 0.8582 \n",
      "Training accuracy 0.5239782\n",
      "Training loss (for one batch): 0.8549 \n",
      "Training accuracy 0.5269854\n",
      "Training loss (for one batch): 0.8561 \n",
      "Training accuracy 0.529842\n",
      "Training loss (for one batch): 0.8508 \n",
      "Training accuracy 0.5325134\n",
      "Training loss (for one batch): 0.8393 \n",
      "Training accuracy 0.53497183\n",
      "Training loss (for one batch): 0.8532 \n",
      "Training accuracy 0.5373134\n",
      "Training loss (for one batch): 0.8495 \n",
      "Training accuracy 0.5395367\n",
      "Training loss (for one batch): 0.8315 \n",
      "Training accuracy 0.54163927\n",
      "Training loss (for one batch): 0.8406 \n",
      "Training accuracy 0.54365724\n",
      "Training loss (for one batch): 0.8555 \n",
      "Training accuracy 0.5455274\n",
      "Training loss (for one batch): 0.8478 \n",
      "Training accuracy 0.54725057\n",
      "Training loss (for one batch): 0.8458 \n",
      "Training accuracy 0.5489334\n",
      "Training loss (for one batch): 0.8343 \n",
      "Training accuracy 0.5505381\n",
      "Training loss (for one batch): 0.8528 \n",
      "Training accuracy 0.5520484\n",
      "Training loss (for one batch): 0.8444 \n",
      "Training accuracy 0.5534617\n",
      "Training loss (for one batch): 0.8316 \n",
      "Training accuracy 0.55485743\n",
      "Training loss (for one batch): 0.8408 \n",
      "Training accuracy 0.5562498\n"
     ]
    }
   ],
   "source": [
    "for constraint in adult_data.constraints:\n",
    "    print(constraint)\n",
    "    \n",
    "fimap = Fimap(constraints=adult_data.constraints + [ValueMonotonicity(['age'], 'increasing')])\n",
    "fimap.fit(adult_data.raw_X_train, model_predictions, epochs=400)\n",
    "\n",
    "\n",
    "dfs = [compare(i, fimap) for i in range(200)]\n",
    "concat_df = pd.concat(dfs)\n",
    "concat_df.to_csv(\"results_normal_constraints_age_increasing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15620a47f84161de3ff2eac7b5580bb2a18e35c2e6a3d277430255ba85aee0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
