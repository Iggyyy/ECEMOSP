{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THIS VARIABLE IF \n",
    "explained_model_backend = 'sklearn' # 'sklearn' or 'tensorflow'\n",
    "\n",
    "# WARNING REMEMEBER TO CHANGE MANUALLY CFEC MODEL LOADING IF SOME CHANGES APPEAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from utils.transformations import min_max_normalization, inverse_min_max_normalization, transform_to_sparse, inverse_transform_to_sparse\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning) #Ignore sklearn \"RF fitted with FeatureNames\"\n",
    "\n",
    "train_dataset = pd.read_csv(\"../data/adult.csv\")\n",
    "dataset_name = 'adult'\n",
    "instance_to_explain_index = 20999\n",
    "\n",
    "with open('../data/adult_constraints.json', 'r') as f:\n",
    "    constr = json.load(f)\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    # SKLEARN\n",
    "    with open('../models/adult_RF.pkl', 'rb') as f:\n",
    "        explained_model = pickle.load(f)\n",
    "else: \n",
    "    # TENSORFLOW\n",
    "    explained_model = tf.keras.models.load_model('../models/adult_NN/')\n",
    "\n",
    "\n",
    "train_dataset = train_dataset[constr['features_order_nonsplit']]\n",
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_mask_indices_sparse = [1 if any([act in x for act in constr['actionable_features']]) else 0 for x in constr['features_order_after_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = train_dataset.drop(columns=\"income\")[instance_to_explain_index:instance_to_explain_index+1]\n",
    "\n",
    "all_counterfactuals = pd.DataFrame(columns=train_dataset.columns.tolist() + ['explainer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataset to sparse\n",
    "train_dataset_sparse = transform_to_sparse(\n",
    "    _df=train_dataset.drop(columns=\"income\"),\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Min-max normalization\n",
    "train_dataset_sparse_normalized = min_max_normalization(\n",
    "    _df=train_dataset_sparse,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "query_instance_sparse_normalized = train_dataset_sparse_normalized[instance_to_explain_index:instance_to_explain_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice import DiceModel\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    dice_model = DiceModel(\n",
    "        train_dataset=train_dataset,\n",
    "        continuous_features=constr['continuous_features_nonsplit'],\n",
    "        categorical_features=constr['categorical_features_nonsplit'],\n",
    "        target=constr['target_feature'],\n",
    "        model_path='../models/adult_RF.pkl',\n",
    "        backend='sklearn',\n",
    "        func='ohe-min-max',\n",
    "    )\n",
    "else:\n",
    "    dice_model = DiceModel(\n",
    "        train_dataset=train_dataset,\n",
    "        continuous_features=constr['continuous_features_nonsplit'],\n",
    "        categorical_features=constr['categorical_features_nonsplit'],\n",
    "        target=constr['target_feature'],\n",
    "        model_path='../models/adult_NN/',\n",
    "        backend='TF2',\n",
    "        func='ohe-min-max',\n",
    "    )\n",
    "\n",
    "dice_counterfactuals_df = dice_model.generate_counterfactuals(\n",
    "    query_instance=query_instance,\n",
    "    total_CFs=20,\n",
    "    desired_class='opposite',\n",
    "    features_to_vary=constr['actionable_features'],\n",
    "    permitted_range=constr['feature_ranges'],\n",
    ")\n",
    "\n",
    "dice_counterfactuals_df['explainer'] = 'dice'\n",
    "all_counterfactuals = pd.concat([all_counterfactuals, dice_counterfactuals_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counterfactuals.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(actionable_mask_indices_sparse)[0].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfec_ece import CfecEceModel \n",
    "\n",
    "train_dataset_sparse_normalized_subsample = train_dataset_sparse_normalized.sample(frac=1.0)\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    cfec_model = CfecEceModel(\n",
    "        train_data_normalized=train_dataset_sparse_normalized_subsample,\n",
    "        constraints_dictionary=constr,\n",
    "        model_path='../models/adult_RF.pkl',\n",
    "        model_backend='sklearn',\n",
    "        fimap_load_s_g_full_id=f'adult_sklearn|2023-01-17',\n",
    "        #fimap_save_s_q_prefix='adult_sklearn',\n",
    "        columns_to_change=np.where(actionable_mask_indices_sparse)[0].tolist(),\n",
    "        )\n",
    "else:\n",
    "    cfec_model = CfecEceModel(\n",
    "        train_data_normalized=train_dataset_sparse_normalized_subsample,\n",
    "        constraints_dictionary=constr,\n",
    "        model_path='../models/adult_NN/',\n",
    "        model_backend='tensorflow',\n",
    "        fimap_load_s_g_full_id=f'adult_tensorflow|2023-01-17',\n",
    "        #fimap_save_s_q_prefix='adult_tensorflow',\n",
    "        columns_to_change=np.where(actionable_mask_indices_sparse)[0].tolist(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfec_counterfactuals_raw, list_cfs_explainers = cfec_model.generate_counterfactuals(query_instance=query_instance_sparse_normalized.iloc[0])\n",
    "cfec_counterfactuals_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not allow for negative values\n",
    "cfec_counterfactuals_raw[cfec_counterfactuals_raw < 0] = 0\n",
    "\n",
    "# Inverse min-max normalization\n",
    "cfec_counterfactuals = inverse_min_max_normalization(\n",
    "    _df=cfec_counterfactuals_raw,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Inverse transform to sparse\n",
    "cfec_counterfactuals = inverse_transform_to_sparse(\n",
    "    sparse_df=cfec_counterfactuals,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cfs_explainers = list(map(lambda x: 'Cadex' if 'Cadex' in x else 'Fimap', list_cfs_explainers))\n",
    "cfec_counterfactuals['explainer'] = list_cfs_explainers\n",
    "all_counterfactuals = pd.concat([all_counterfactuals, cfec_counterfactuals], ignore_index=True)\n",
    "cfec_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance_sparse_normalized[cfec_counterfactuals_raw.columns[39:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfec_counterfactuals_raw[cfec_counterfactuals_raw.columns[39:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WACHTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_impl import AlibiWachter\n",
    "\n",
    "continous = len(constr['continuous_features_nonsplit'])\n",
    "eps_wachter = np.array([[0.1] * continous + [1.0] * (len(train_dataset_sparse_normalized.columns) - continous)]) * (np.array(actionable_mask_indices_sparse, dtype=int) + 0.001)\n",
    "#eps_wachter = 0.1\n",
    "\n",
    "# Dont allow perturbations on non-actionable features\n",
    "#eps_wachter = actionable_mask_indices_sparse * eps_wachter\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    wachter_model = AlibiWachter('../models/adult_RF.pkl', 'sklearn', query_instance_sparse_normalized.shape, eps=eps_wachter)\n",
    "else:\n",
    "    wachter_model = AlibiWachter('../models/adult_NN/', 'tensorflow', query_instance_sparse_normalized.shape, eps=eps_wachter)\n",
    "    \n",
    "explanation = wachter_model.generate_counterfactuals(query_instance_sparse_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wachter_counterfactuals = []\n",
    "for key, lst in explanation['data']['all'].items():\n",
    "    if lst:\n",
    "        for cf in lst:\n",
    "            wachter_counterfactuals.append(cf['X'])\n",
    "\n",
    "wachter_counterfactuals = np.array(wachter_counterfactuals).reshape(-1, query_instance_sparse_normalized.shape[1])\n",
    "\n",
    "wachter_counterfactuals_df = pd.DataFrame(wachter_counterfactuals, columns=constr['features_order_after_split'])\n",
    "\n",
    "# Inverse min-max normalization\n",
    "wachter_counterfactuals_df = inverse_min_max_normalization(\n",
    "    _df=wachter_counterfactuals_df,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Inverse transform to sparse\n",
    "wachter_counterfactuals_df = inverse_transform_to_sparse(\n",
    "    sparse_df=wachter_counterfactuals_df,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "wachter_counterfactuals_df['explainer'] = 'wachter'\n",
    "\n",
    "# Reduce number of Wachter counterfactuals because they are almost the same\n",
    "sampled_wachter_cfs = wachter_counterfactuals_df.sample(min(len(wachter_counterfactuals_df), 40))\n",
    "\n",
    "all_counterfactuals = pd.concat([all_counterfactuals, sampled_wachter_cfs], ignore_index=True)\n",
    "\n",
    "wachter_counterfactuals_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wachter_counterfactuals_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import CEM\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "shape = query_instance_sparse_normalized.shape  # instance shape\n",
    "continous = len(constr['continuous_features_nonsplit'])\n",
    "clip = (-1000.,1000.)\n",
    "eps_cem = (\n",
    "        0.01,\n",
    "        np.array([[0.01] * continous + [1.0] * (len(train_dataset_sparse_normalized.columns) - continous)]) #* actionable_mask_indices_sparse # Dont allow changes on non-actionable features\n",
    "        )\n",
    "\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    mode = 'PN'\n",
    "    feature_range = (train_dataset_sparse_normalized.to_numpy().min(),  # feature range for the perturbed instance\n",
    "                    train_dataset_sparse_normalized.to_numpy().max()) \n",
    "    update_num_grad = 10\n",
    "    c_init = 1.  # initial weight c of the loss term encouraging to predict a different class (PN) or\n",
    "                # the same class (PP) for the perturbed instance compared to the original instance to be explained\n",
    "    # Return probabilities for x\n",
    "    cem_pred_fn = lambda x: np.array(explained_model.predict_proba(x)[0])#explained_model.predict_proba(x)[0][0][::-1].reshape(1, 2)#np.array([explained_model.predict_proba(x)[0][0][1], explained_model.predict_proba(x)[0][0][0]])\n",
    "\n",
    "    cem = CEM(cem_pred_fn, mode, shape, kappa=0.0, beta=0.1, feature_range=feature_range, \n",
    "            eps=eps_cem, update_num_grad=update_num_grad, clip=clip, no_info_val=-0.0, c_init=c_init,\n",
    "            c_steps=10, learning_rate_init=.8, max_iterations=100\n",
    "            )\n",
    "else:\n",
    "    mode = 'PN'  # 'PN' (pertinent negative) or 'PP' (pertinent positive)\n",
    "    kappa = .2  # minimum difference needed between the prediction probability for the perturbed instance on the\n",
    "                # class predicted by the original instance and the max probability on the other classes\n",
    "                # in order for the first loss term to be minimized\n",
    "    beta = .1  # weight of the L1 loss term\n",
    "    c_init = 10  # initial weight c of the loss term encouraging to predict a different class (PN) or\n",
    "                # the same class (PP) for the perturbed instance compared to the original instance to be explained\n",
    "   \n",
    "    c_steps = 10  # nb of updates for c\n",
    "    max_iterations = 1000  # nb of iterations per value of c\n",
    "    feature_range = (train_dataset_sparse_normalized.to_numpy().min(axis=0).reshape(shape)-.1,  # feature range for the perturbed instance\n",
    "                    train_dataset_sparse_normalized.to_numpy().max(axis=0).reshape(shape)+.1)  # can be either a float or array of shape (1xfeatures)\n",
    "      # gradient clipping\n",
    "    lr_init = 1e-2  # initial learning rate\n",
    "\n",
    "    # initialize CEM explainer and explain instance\n",
    "    cem = CEM(explained_model, mode, shape, kappa=kappa, beta=beta, feature_range=feature_range,\n",
    "            max_iterations=max_iterations, c_init=c_init, c_steps=c_steps,\n",
    "            learning_rate_init=lr_init, clip=clip)\n",
    "\n",
    "cem.fit(train_dataset_sparse_normalized.to_numpy(), no_info_type='median')  # we need to define what feature values contain the least\n",
    "                                                                    # info wrt predictions\n",
    "                                                                    # here we will naively assume that the feature-wise median\n",
    "                                                                    # contains no info; domain knowledge helps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cem_explanation = cem.explain(query_instance_sparse_normalized, verbose=True)\n",
    "\n",
    "cem_cf_df = pd.DataFrame(cem_explanation.PN, columns=constr['features_order_after_split'])\n",
    "\n",
    "# Inverse min-max normalization\n",
    "cem_cf_df = inverse_min_max_normalization(\n",
    "    _df=cem_cf_df,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Inverse transform to sparse\n",
    "cem_cf_df = inverse_transform_to_sparse(\n",
    "    sparse_df=cem_cf_df,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "cem_cf_df['explainer'] = 'Cem'\n",
    "\n",
    "all_counterfactuals = pd.concat([all_counterfactuals, cem_cf_df], ignore_index=True)\n",
    "\n",
    "cem_cf_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFPROTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from alibi.explainers import CounterfactualProto\n",
    "\n",
    "# import pickle\n",
    "# with open('../models/adult_RF.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)\n",
    "# predict_fnct = lambda x: model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_vars_ord = {}\n",
    "# for i, cat in enumerate(constr['categorical_features_nonsplit']):\n",
    "#     start_index = np.argwhere(cat == train_dataset.columns.to_numpy())[0][0]\n",
    "#     unique = len(np.unique(train_dataset[cat]))\n",
    "#     cat_vars_ord[start_index] = unique\n",
    "# print(cat_vars_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfProto = CounterfactualProto(predict_fnct,\n",
    "#                          query_instance_sparse_normalized.shape,\n",
    "#                          cat_vars=cat_vars_ord,\n",
    "#                          ohe=True,  # OHE flag\n",
    "#                          max_iterations=500,\n",
    "#                          beta=0.01,\n",
    "#                          feature_range=(0.0, 1.0),\n",
    "#                          use_kdtree=True,\n",
    "#                          theta= 10.,\n",
    "#                          c_init=1.0,\n",
    "#                          c_steps=5,\n",
    "#                         )\n",
    "# cfProto.fit(train_dataset_sparse_normalized.to_numpy(), d_type='abdm', trustscore_kwargs=None)\n",
    "# explanation = cfProto.explain(query_instance_sparse_normalized.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_helpers import get_scores\n",
    "from visualization_helpers import remove_duplicates\n",
    "\n",
    "all_counterfactuals = remove_duplicates(all_counterfactuals)\n",
    "print('Counterfactuals: ', all_counterfactuals.shape)\n",
    "\n",
    "# Transform counterfactuals to sparse\n",
    "counterfactuals_sparse = transform_to_sparse(\n",
    "    _df=all_counterfactuals,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Normalize counterfactuals\n",
    "counterfactuals_sparse_normalized = min_max_normalization(\n",
    "    _df=counterfactuals_sparse,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "\n",
    "# Transform query instance to sparse\n",
    "query_instance_sparse = transform_to_sparse(\n",
    "    _df=query_instance,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    categorical_features=constr['categorical_features_nonsplit'],\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Normalize query instance sparse\n",
    "query_instance_sparse_normalized = min_max_normalization(\n",
    "    _df=query_instance_sparse,\n",
    "    original_df=train_dataset.drop(columns=\"income\"),\n",
    "    continuous_features=constr['continuous_features_nonsplit']\n",
    ")\n",
    "\n",
    "# Mask non actionable features\n",
    "mask_indices = [1 if any([act in x for act in constr['actionable_features']]) else 0 for x in constr['features_order_after_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cems = all_counterfactuals[all_counterfactuals['explainer'] == 'Cem'].index.tolist()\n",
    "wachters = all_counterfactuals[all_counterfactuals['explainer'] == 'wachter'].index.tolist()\n",
    "cadexes = all_counterfactuals[all_counterfactuals['explainer'] == 'Cadex'].index.tolist()\n",
    "fimaps = all_counterfactuals[all_counterfactuals['explainer'] == 'Fimap'].index.tolist()\n",
    "\n",
    "\n",
    "print('Orginal x: ',explained_model.predict_proba(query_instance_sparse_normalized)[0] )\n",
    "\n",
    "if len(cems) > 0:\n",
    "    print('cem: ', explained_model.predict_proba(counterfactuals_sparse_normalized.iloc[cems].to_numpy().reshape(-1, 85))[0])\n",
    "if len(wachters) > 0:\n",
    "    print('wachters: ', explained_model.predict_proba(counterfactuals_sparse_normalized.iloc[wachters].to_numpy().reshape(-1, 85))[0])\n",
    "if len(cadexes) > 0:\n",
    "    print('cadexes: ', explained_model.predict_proba(counterfactuals_sparse_normalized.iloc[cadexes].to_numpy().reshape(-1, 85))[0])\n",
    "if len(fimaps) > 0:\n",
    "    print('fimaps: ', explained_model.predict_proba(counterfactuals_sparse_normalized.iloc[fimaps].to_numpy().reshape(-1, 85))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_helpers import filter_non_valid\n",
    "from visualization_helpers import filter_non_actionable\n",
    "\n",
    "# # SKLEARN\n",
    "# with open('../models/adult_RF.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)\n",
    "\n",
    "# # TENSORFLOW\n",
    "# model = tf.keras.models.load_model('../models/adult_NN/')\n",
    "\n",
    "if explained_model_backend == 'sklearn':\n",
    "    # SKLEARN\n",
    "    with open('../models/adult_RF.pkl', 'rb') as f:\n",
    "        explained_model = pickle.load(f)\n",
    "else: \n",
    "    # TENSORFLOW\n",
    "    explained_model = tf.keras.models.load_model('../models/adult_NN/')\n",
    "\n",
    "predict_fn = lambda x: explained_model.predict(x)\n",
    "\n",
    "valid_counterfactuals_sparse_normalized = filter_non_valid(predict_fn, query_instance_sparse_normalized, counterfactuals_sparse_normalized)\n",
    "valid_counterfactuals_sparse_normalized.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter not feasible (data is min-max normalized, so values shouldn't be less than zero)\n",
    "# not_feasible = np.where(np.sum(counterfactuals_sparse_normalized < 0, axis=1) > 0)[0]\n",
    "not_feasible = []\n",
    "\n",
    "indices_to_keep = list(filter(lambda x: x not in not_feasible, valid_counterfactuals_sparse_normalized.index.tolist()))\n",
    "valid_counterfactuals_sparse_normalized = counterfactuals_sparse_normalized.iloc[indices_to_keep]\n",
    "print(indices_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_counterfactuals_sparse_normalized.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counterfactuals.iloc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_counterfactuals = all_counterfactuals.iloc[indices_to_keep]\n",
    "valid_counterfactuals.reset_index(drop=True, inplace=True)\n",
    "valid_counterfactuals = filter_non_actionable(valid_counterfactuals, query_instance, constr['non_actionable_features'])\n",
    "valid_counterfactuals_sparse_normalized = valid_counterfactuals_sparse_normalized.iloc[valid_counterfactuals.index.tolist()]\n",
    "valid_counterfactuals_sparse_normalized.reset_index(drop=True, inplace=True)\n",
    "valid_counterfactuals.reset_index(drop=True, inplace=True)\n",
    "valid_counterfactuals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add income column\n",
    "valid_counterfactuals['income'] = np.argmax(predict_fn(valid_counterfactuals_sparse_normalized.to_numpy()[0:1]))\n",
    "valid_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = get_scores(valid_counterfactuals_sparse_normalized.to_numpy(), query_instance_sparse_normalized, train_dataset_sparse_normalized, train_dataset['income'], mask_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['explainer'] = valid_counterfactuals['explainer']\n",
    "scores_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# We want to plot only subset of columns \n",
    "scores_to_plot = scores_df.drop(['cf', 'actionability', 'preference_dcg', 'discriminative_power'], axis=1)\n",
    "\n",
    "# # Pairplot\n",
    "# sns.pairplot(scores_to_plot, hue=\"explainer\", diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sklearn' in str(type(explained_model)):\n",
    "    explained_model_name = 'RF'\n",
    "else:\n",
    "    explained_model_name = 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from visualization_helpers import get_pareto_frontier_mask\n",
    "\n",
    "\n",
    "metrics_to_plot = ['proximity', 'features_changed', 'feasibility', 'dispreference_dcg', 'non_discriminative_power']\n",
    "n = len(metrics_to_plot)\n",
    "\n",
    "fig, ax = plt.subplots(n, n, figsize=(3.5*n, 3*n))\n",
    "\n",
    "colors = ['r', 'g', 'b', 'y', 'c', 'm', 'k', 'w']\n",
    "markers = ['s', 'o', 'v', '+', '*', 'p', 'P', 'X', 'D', '>']\n",
    "labels = []\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "for plot_round in ['nonpareto', 'pareto']:\n",
    "    for i, other_metric in enumerate(metrics_to_plot):\n",
    "        for j, metric in enumerate(metrics_to_plot):\n",
    "\n",
    "            all_x = scores_df[metric].to_numpy()\n",
    "            all_y = scores_df[other_metric].to_numpy()\n",
    "            to_check = np.array([all_x, all_y], dtype=np.float64).T\n",
    "            all_pareto = get_pareto_frontier_mask(to_check)\n",
    "            ax[i*n+j].grid()\n",
    "\n",
    "            for k, explainer in enumerate(scores_df['explainer'].value_counts().sort_values(ascending=True).index.tolist()):\n",
    "\n",
    "                mask = scores_df['explainer'] == explainer\n",
    "                pareto = all_pareto[mask]\n",
    "\n",
    "                x = scores_df[mask][metric].to_numpy()\n",
    "                y = scores_df[mask][other_metric].to_numpy()\n",
    "            \n",
    "                if plot_round == 'nonpareto':\n",
    "                    if i == j:\n",
    "                        ax[i*n+j].hist(x, color=colors[k], label=explainer, alpha=0.5)\n",
    "                        ax[i*n+j].legend()\n",
    "                    else:\n",
    "                        ax[i*n+j].scatter(x[~pareto], y[~pareto], color='steelblue', marker=markers[k], label=explainer)\n",
    "                elif plot_round == 'pareto' and i!=j:\n",
    "                    ax[i*n+j].scatter(x[pareto], y[pareto], color='orange', marker=markers[k])\n",
    "\n",
    "                    if i < j:\n",
    "                        print(f'For explainer: {explainer} and metrics {metric}, {other_metric}, paretos: {sum(pareto)} out of {len(pareto)}')\n",
    "                        # print(f'{scores_df[scores_df[\"explainer\"] == explainer][[metric, other_metric]][pareto]}')\n",
    "            \n",
    "            ax[i*n+j].set_xlabel(metric)\n",
    "            ax[i*n+j].set_ylabel(other_metric)\n",
    "    # plt.title('Proximity vs Dispreference DCG \\n(Pareto front in orange). \\nLower is better.')\n",
    "\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right')\n",
    "\n",
    "counts = scores_df['explainer'].value_counts()\n",
    "\n",
    "plt.suptitle(f'Pareto frontiers of the counterfactuals (lower is better)\\nExplained model: {explained_model_name}\\nDataset: {dataset_name}\\nCounterfactuals by method {counts.to_dict()}\\n')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../images/{dataset_name}/{explained_model_name}/{dataset_name}_pairplot_with_frontiers_{instance_to_explain_index}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[['feasibility', 'features_changed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'feasibility'\n",
    "other_metric = 'features_changed'\n",
    "all_x = scores_df[metric].to_numpy()\n",
    "all_y = scores_df[other_metric].to_numpy()\n",
    "to_check = np.array([all_x, all_y], dtype=np.float64).T\n",
    "all_pareto = get_pareto_frontier_mask(to_check)\n",
    "scores_df[[metric, other_metric, 'explainer']][all_pareto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['explainer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81d0d6994cbc9a338f9a3d74dedf5823f97cddc544b8ee56d3ad85196f930114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
