{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "#from modules.CARLA import carla\n",
    "\n",
    "seed = 44\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from carla.data.catalog import CsvCatalog\n",
    "# import json\n",
    "\n",
    "# with open('../data/adult_constraints.json', 'r') as f:\n",
    "#     constraints = json.load(f)\n",
    "\n",
    "# continuous = constraints['continuous']\n",
    "# categorical = constraints['categorical']\n",
    "# immutable = constraints['immutable']\n",
    "# columns_order = constraints['features_order']\n",
    "\n",
    "# dataset = CsvCatalog(file_path=\"../data/adult_prep.csv\",\n",
    "#                     continuous=continuous,\n",
    "#                     categorical=categorical,\n",
    "#                     immutables=immutable,\n",
    "#                     target='income')\n",
    "# dataset.df.to_csv(\"../data/adult_prep_test.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "# X_train = dataset.df_train\n",
    "# Y_train = dataset.df_train\n",
    "# X_test = dataset.df_test\n",
    "# Y_test = dataset.df_test\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['capital.gain', 'capital.loss', 'hours.per.week', 'age',\n",
       "       'education.num', 'workclass_?', 'workclass_Federal-gov',\n",
       "       'workclass_Local-gov', 'workclass_Never-worked', 'workclass_Private',\n",
       "       'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc',\n",
       "       'workclass_State-gov', 'workclass_Without-pay',\n",
       "       'marital.status_Divorced', 'marital.status_Married-AF-spouse',\n",
       "       'marital.status_Married-civ-spouse',\n",
       "       'marital.status_Married-spouse-absent', 'marital.status_Never-married',\n",
       "       'marital.status_Separated', 'marital.status_Widowed', 'occupation_?',\n",
       "       'occupation_Adm-clerical', 'occupation_Armed-Forces',\n",
       "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
       "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
       "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
       "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
       "       'occupation_Protective-serv', 'occupation_Sales',\n",
       "       'occupation_Tech-support', 'occupation_Transport-moving',\n",
       "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
       "       'race_Other', 'race_White', 'sex_Female', 'sex_Male',\n",
       "       'native.country_?', 'native.country_Cambodia', 'native.country_Canada',\n",
       "       'native.country_China', 'native.country_Columbia',\n",
       "       'native.country_Cuba', 'native.country_Dominican-Republic',\n",
       "       'native.country_Ecuador', 'native.country_El-Salvador',\n",
       "       'native.country_England', 'native.country_France',\n",
       "       'native.country_Germany', 'native.country_Greece',\n",
       "       'native.country_Guatemala', 'native.country_Haiti',\n",
       "       'native.country_Holand-Netherlands', 'native.country_Honduras',\n",
       "       'native.country_Hong', 'native.country_Hungary', 'native.country_India',\n",
       "       'native.country_Iran', 'native.country_Ireland', 'native.country_Italy',\n",
       "       'native.country_Jamaica', 'native.country_Japan', 'native.country_Laos',\n",
       "       'native.country_Mexico', 'native.country_Nicaragua',\n",
       "       'native.country_Outlying-US(Guam-USVI-etc)', 'native.country_Peru',\n",
       "       'native.country_Philippines', 'native.country_Poland',\n",
       "       'native.country_Portugal', 'native.country_Puerto-Rico',\n",
       "       'native.country_Scotland', 'native.country_South',\n",
       "       'native.country_Taiwan', 'native.country_Thailand',\n",
       "       'native.country_Trinadad&Tobago', 'native.country_United-States',\n",
       "       'native.country_Vietnam', 'native.country_Yugoslavia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('../data/adult_constraints.json', 'r') as f:\n",
    "    constr = json.load(f)\n",
    "\n",
    "dataset = pd.read_csv(\"../data/adult_cleaned.csv\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[constr['features_order_after_split']], dataset['income'], test_size=0.2, random_state=seed)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20789     >50K\n",
       "7665     <=50K\n",
       "7003     <=50K\n",
       "3368     <=50K\n",
       "15072    <=50K\n",
       "         ...  \n",
       "16955    <=50K\n",
       "25773     >50K\n",
       "27377    <=50K\n",
       "3491     <=50K\n",
       "14100    <=50K\n",
       "Name: income, Length: 26048, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = X_train.to_numpy()\n",
    "Y_train = Y_train\n",
    "Y_train = pd.get_dummies(Y_train).to_numpy()\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.to_numpy()\n",
    "Y_test = Y_test\n",
    "Y_test = pd.get_dummies(Y_test).to_numpy()\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 85)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constr['features_count_split_without_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2397, 0.7603])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = np.round(1 - Y_train.sum(axis=0) / Y_train.sum(), 4)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.2397, 1: 0.7603}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "tf_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input((constr['features_count_split_without_target'],)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 3s 27ms/step - loss: 0.2299 - accuracy: 0.6171 - val_loss: 0.5132 - val_accuracy: 0.7321\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.1867 - accuracy: 0.7388 - val_loss: 0.4608 - val_accuracy: 0.7408\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1753 - accuracy: 0.7494 - val_loss: 0.4495 - val_accuracy: 0.7503\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1681 - accuracy: 0.7579 - val_loss: 0.4214 - val_accuracy: 0.7723\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1666 - accuracy: 0.7573 - val_loss: 0.4325 - val_accuracy: 0.7619\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1628 - accuracy: 0.7678 - val_loss: 0.4220 - val_accuracy: 0.7801\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1589 - accuracy: 0.7769 - val_loss: 0.4027 - val_accuracy: 0.7915\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1573 - accuracy: 0.7776 - val_loss: 0.4108 - val_accuracy: 0.7827\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1550 - accuracy: 0.7810 - val_loss: 0.4145 - val_accuracy: 0.7855\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1533 - accuracy: 0.7837 - val_loss: 0.4012 - val_accuracy: 0.7972\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1521 - accuracy: 0.7868 - val_loss: 0.4145 - val_accuracy: 0.7827\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1498 - accuracy: 0.7903 - val_loss: 0.4068 - val_accuracy: 0.7889\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1475 - accuracy: 0.7945 - val_loss: 0.3974 - val_accuracy: 0.8002\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1477 - accuracy: 0.7937 - val_loss: 0.4013 - val_accuracy: 0.7952\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1455 - accuracy: 0.7986 - val_loss: 0.3877 - val_accuracy: 0.8076\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1450 - accuracy: 0.7969 - val_loss: 0.3916 - val_accuracy: 0.7995\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1435 - accuracy: 0.8029 - val_loss: 0.3783 - val_accuracy: 0.8085\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1438 - accuracy: 0.8014 - val_loss: 0.3949 - val_accuracy: 0.8030\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1431 - accuracy: 0.8028 - val_loss: 0.3864 - val_accuracy: 0.8030\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1416 - accuracy: 0.8008 - val_loss: 0.4077 - val_accuracy: 0.7880\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1418 - accuracy: 0.8004 - val_loss: 0.3726 - val_accuracy: 0.8119\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1410 - accuracy: 0.8012 - val_loss: 0.3890 - val_accuracy: 0.8009\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.1401 - accuracy: 0.8031 - val_loss: 0.4018 - val_accuracy: 0.7936\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1393 - accuracy: 0.8044 - val_loss: 0.4107 - val_accuracy: 0.7886\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1394 - accuracy: 0.8048 - val_loss: 0.3751 - val_accuracy: 0.8096\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1377 - accuracy: 0.8064 - val_loss: 0.3841 - val_accuracy: 0.8067\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1376 - accuracy: 0.8069 - val_loss: 0.3808 - val_accuracy: 0.8081\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1374 - accuracy: 0.8079 - val_loss: 0.3826 - val_accuracy: 0.8095\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1363 - accuracy: 0.8089 - val_loss: 0.3852 - val_accuracy: 0.8029\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.1364 - accuracy: 0.8085 - val_loss: 0.3722 - val_accuracy: 0.8115\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1362 - accuracy: 0.8084 - val_loss: 0.3812 - val_accuracy: 0.8029\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1356 - accuracy: 0.8118 - val_loss: 0.3817 - val_accuracy: 0.8085\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1350 - accuracy: 0.8130 - val_loss: 0.3862 - val_accuracy: 0.8033\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1352 - accuracy: 0.8095 - val_loss: 0.3864 - val_accuracy: 0.8055\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1354 - accuracy: 0.8112 - val_loss: 0.3726 - val_accuracy: 0.8128\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1351 - accuracy: 0.8118 - val_loss: 0.3943 - val_accuracy: 0.7924\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1350 - accuracy: 0.8076 - val_loss: 0.3928 - val_accuracy: 0.7996\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1340 - accuracy: 0.8097 - val_loss: 0.3867 - val_accuracy: 0.8050\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.1343 - accuracy: 0.8148 - val_loss: 0.3917 - val_accuracy: 0.8015\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.1332 - accuracy: 0.8125 - val_loss: 0.3811 - val_accuracy: 0.8087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1426ffb4d90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "    ],\n",
    "    verbose=1,\n",
    "    class_weight=tf_class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/adult_NN.h5', overwrite=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/adult_NN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/adult_NN\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.4801334e-01, 1.5198670e-01],\n",
       "       [9.9952066e-01, 4.7937059e-04]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('../models/adult_NN', overwrite=True)\n",
    "model_test = tf.keras.models.load_model('../models/adult_NN.h5')\n",
    "model_test.predict(X_test[0:2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/adult_NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.321678e-01, 6.783224e-02],\n",
       "       [9.990681e-01, 9.319379e-04]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0:2], verbose=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best! Crit: gini, Max_depth: 10, Max_feat: sqrt, Min_sampl_leaf: 2 MIn_samples_split 2, Min_impurity_dec: 0, Estimators: 150 Score: 0.6961461692000614\n",
      "New Best! Crit: gini, Max_depth: 10, Max_feat: sqrt, Min_sampl_leaf: 3 MIn_samples_split 3, Min_impurity_dec: 0, Estimators: 150 Score: 0.699677567941041\n",
      "New Best! Crit: gini, Max_depth: 30, Max_feat: sqrt, Min_sampl_leaf: 2 MIn_samples_split 2, Min_impurity_dec: 0, Estimators: 150 Score: 0.8252725318593582\n",
      "New Best! Crit: gini, Max_depth: None, Max_feat: sqrt, Min_sampl_leaf: 2 MIn_samples_split 2, Min_impurity_dec: 0, Estimators: 150 Score: 0.839091048671887\n",
      "New Best! Crit: gini, Max_depth: None, Max_feat: sqrt, Min_sampl_leaf: 3 MIn_samples_split 3, Min_impurity_dec: 0, Estimators: 150 Score: 0.8453861507753724\n",
      "New Best! Crit: gini, Max_depth: None, Max_feat: sqrt, Min_sampl_leaf: 4 MIn_samples_split 4, Min_impurity_dec: 0, Estimators: 150 Score: 0.8466144633809305\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "\n",
    "for crit in ['gini', 'entropy']:\n",
    "    for max_depth in [10, 30, None]: \n",
    "        for estimators in [150, 200]:\n",
    "            for max_features in ['sqrt', 'log2']:\n",
    "                for min_samples_leaf in [1,2,3]:\n",
    "                    for min_samples_split in [2,3,4]:\n",
    "                        for min_impurity_decrease in [0, 0.001, 0.01, 0.1]:\n",
    "                            classifier = RandomForestClassifier(\n",
    "                                random_state=seed, \n",
    "                                criterion=crit, \n",
    "                                n_estimators=estimators,\n",
    "                                verbose=0,\n",
    "                                class_weight='balanced',\n",
    "                                min_impurity_decrease=min_impurity_decrease,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                max_depth=max_depth,\n",
    "                                n_jobs=3,\n",
    "                                max_features=max_features\n",
    "                                )\n",
    "                            classifier.fit(X_train, Y_train)\n",
    "                            score = classifier.score(X_test, Y_test)\n",
    "                            if score > best_score:\n",
    "                                best_score = score\n",
    "                                print(f'New Best! Crit: {crit}, Max_depth: {max_depth}, Max_feat: {max_features}, Min_sampl_leaf: {min_samples_split} \\\n",
    "MIn_samples_split {min_samples_split}, Min_impurity_dec: {min_impurity_decrease}, Estimators: {estimators} Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839091048671887"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(\n",
    "                random_state=seed, \n",
    "                criterion='gini', \n",
    "                n_estimators=150,\n",
    "                verbose=0,\n",
    "                class_weight='balanced',\n",
    "                min_impurity_decrease=0,\n",
    "                max_depth=None,\n",
    "                n_jobs=3,\n",
    "                max_features='sqrt'\n",
    "            )\n",
    "classifier.fit(X_train, Y_train)\n",
    "classifier.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/adult_RF.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, '../models/adult_RF.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('../models/adult_RF.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_test[0:5])\n",
    "clf.predict(X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/adult_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "with open('../models/adult_RF.pkl', 'rb') as f:\n",
    "    clf_pickl = pickle.load(f)\n",
    "\n",
    "pred = clf_pickl.predict(X_test[0:5])\n",
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03333333, 0.96666667],\n",
       "       [0.00666667, 0.99333333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01848003, 0.98151997],\n",
       "       [0.95333333, 0.04666667],\n",
       "       [0.34464258, 0.65535742],\n",
       "       [0.00666667, 0.99333333],\n",
       "       [0.37333333, 0.62666667],\n",
       "       [0.79333333, 0.20666667],\n",
       "       [0.18460443, 0.81539557]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pickl.predict_proba(X_test[0:10])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81d0d6994cbc9a338f9a3d74dedf5823f97cddc544b8ee56d3ad85196f930114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
