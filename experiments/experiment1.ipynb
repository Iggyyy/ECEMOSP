{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from experiment_utils import load_data, get_closest_to_optimal_point, get_pareto_optimal_mask, get_ideal_point\n",
    "\n",
    "dataset = 'german'\n",
    "date = '2023-03-12'\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'experiments', date, 'scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered scores for 23 instances\n"
     ]
    }
   ],
   "source": [
    "# Load scores\n",
    "list_of_scores_df , scores_df_all, scores_test_set_indices = load_data('scores', date, dataset)\n",
    "print(f'Gathered scores for {len(list_of_scores_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered valid_scores for 23 instances\n"
     ]
    }
   ],
   "source": [
    "# Load valid_scores\n",
    "list_of_valid_scores_df , valid_scores_df_all, valid_scores_test_set_indices = load_data('valid_scores', date, dataset)\n",
    "print(f'Gathered valid_scores for {len(list_of_valid_scores_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered counterfactuals for 23 instances\n"
     ]
    }
   ],
   "source": [
    "# Load counterfactuals\n",
    "list_of_counterfactuals_df , counterfactuals_df_all, cf_test_set_indices = load_data('counterfactuals', date, dataset)\n",
    "print(f'Gathered counterfactuals for {len(list_of_counterfactuals_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered valid_counterfactuals for 23 instances\n"
     ]
    }
   ],
   "source": [
    "# Load valid_counterfactuals\n",
    "list_of_valid_counterfactuals_df , valid_counterfactuals_df_all, valid_cf_test_set_indices = load_data('valid_counterfactuals', date, dataset)\n",
    "print(f'Gathered valid_counterfactuals for {len(list_of_valid_counterfactuals_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data for 23 instances\n"
     ]
    }
   ],
   "source": [
    "# Load test data - original x instances\n",
    "test_data_path = os.path.join(os.getcwd(), 'data', f'{dataset}_test.csv')\n",
    "test_dataset = pd.read_csv(test_data_path).iloc[scores_test_set_indices]\n",
    "print(f'Loaded test data for {len(test_dataset)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded constraints for: german\n"
     ]
    }
   ],
   "source": [
    "# Load constraints for the dataset\n",
    "with open(os.path.join(os.getcwd(), 'data', f'{dataset}_constraints.json'), 'r') as f:\n",
    "    constraints = json.load(f)\n",
    "print(f'Loaded constraints for: {constraints[\"dataset_shortname\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scores_test_set_indices == cf_test_set_indices\n",
    "assert len(list_of_scores_df) == len(list_of_counterfactuals_df) == len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continous indices: [0, 1, 2, 3, 4, 5, 6]\n",
      "Categorical indices: [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Ranges: [   36 13946     3     3    46     1     1]\n",
      "Test plausibility: 5.94\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_ranges(test_data: pd.DataFrame, constraints: dict) -> npt.NDArray:\n",
    "    '''\n",
    "    Get ranges for continous variables.\n",
    "    '''\n",
    "    mins = test_data[constraints['continuous_features_nonsplit']].to_numpy().min(axis=0)\n",
    "    maxes = test_data[constraints['continuous_features_nonsplit']].to_numpy().max(axis=0)\n",
    "    feature_ranges = maxes - mins\n",
    "    return feature_ranges\n",
    "\n",
    "\n",
    "def heom(x: npt.NDArray, y: npt.NDArray, ranges: npt.NDArray, continous_indices: npt.NDArray, categorical_indices: npt.NDArray) -> float:\n",
    "    '''\n",
    "    Calculate HEOM distance between x and y. \n",
    "    X and Y should not be normalized. \n",
    "    X should be (n, m) dimensional.\n",
    "    Y should be 1-D array.\n",
    "    Ranges is max-min on each continous variables (order matters). \n",
    "    '''\n",
    "    distance = np.zeros(x.shape[0])\n",
    "\n",
    "    # Continous |x-y| / range\n",
    "    distance += np.sum(np.abs(x[:, continous_indices].astype('float64') - y[continous_indices].astype('float64')) / ranges, axis=1)\n",
    "\n",
    "    # Categorical - overlap\n",
    "    distance += np.sum(~np.equal(x[:, categorical_indices], y[categorical_indices]), axis=1)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def plausibility(test_data: pd.DataFrame, \n",
    "                 x_index: int, \n",
    "                 counterfactual: pd.DataFrame | pd.Series, \n",
    "                 list_of_counterfactuals_df: List[pd.DataFrame], \n",
    "                 ranges: npt.NDArray, \n",
    "                 continous_indices: npt.NDArray | List[float], \n",
    "                 categorical_indices: npt.NDArray | List[float]\n",
    "                 ):\n",
    "    # Find closest instance to original_x in test_data\n",
    "    n = len(test_data)\n",
    "    x = test_data.iloc[0:n+1].to_numpy()\n",
    "    y = test_data.iloc[x_index].to_numpy()\n",
    "\n",
    "    all_distances = heom(x, y, ranges, continous_indices, categorical_indices)\n",
    "    # find closest instance to original_x in test_data\n",
    "    sorting_indices = np.argsort(all_distances)\n",
    "    # we do not take 0 because it is the same instance as original_x\n",
    "    closest_index = np.array(list(zip(range(n), all_distances)))[sorting_indices][1][0].astype(int)\n",
    "    # counterfactuals of closest x' to x\n",
    "    closest_counterfactuals = list_of_counterfactuals_df[closest_index].to_numpy()\n",
    "    \n",
    "    # x_counterfactuals = list_of_counterfactuals_df[x_index].to_numpy()\n",
    "    # # calculate all pairs of distances between counterfactuals from x and x'\n",
    "    # sum_of_distances = .0\n",
    "    # for x_cf in x_counterfactuals:\n",
    "    #     mean_distance = np.mean(heom(closest_counterfactuals, x_cf, ranges, continous_indices, categorical_indices))\n",
    "    #     sum_of_distances += mean_distance\n",
    "    # return sum_of_distances / len(x_counterfactuals)\n",
    "    \n",
    "    plausibility_score = np.min(heom(closest_counterfactuals, counterfactual.to_numpy(), ranges, continous_indices, categorical_indices))\n",
    "    return plausibility_score\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "continous_indices = [test_dataset.columns.get_loc(c) for c in constraints['continuous_features_nonsplit']]\n",
    "categorical_indices = [test_dataset.columns.get_loc(c) for c in constraints['categorical_features_nonsplit']]\n",
    "ranges = get_ranges(test_dataset, constraints)\n",
    "\n",
    "print(f'Continous indices: {continous_indices}')\n",
    "print(f'Categorical indices: {categorical_indices}')\n",
    "print(f'Ranges: {ranges}')\n",
    "\n",
    "test_plaus = plausibility(test_dataset, 0, list_of_counterfactuals_df[0].iloc[0], list_of_counterfactuals_df, ranges, continous_indices, categorical_indices)\n",
    "# Calculate example plausibility score\n",
    "print(f'Test plausibility: {test_plaus:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(x_instance: npt.NDArray, cf_instance: npt.NDArray, continous_indices, categorical_indices) -> int:\n",
    "    _sparsity = 0\n",
    "    \n",
    "    # Continous\n",
    "    _sparsity += np.sum(~np.isclose(x_instance[continous_indices].astype('float64'), cf_instance[continous_indices].astype('float64'), atol=1e-05))\n",
    "    \n",
    "    # Categorical\n",
    "    _sparsity += np.sum(~np.equal(x_instance[categorical_indices].astype('str'), cf_instance[categorical_indices].astype('str')))\n",
    "    \n",
    "    return _sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_actionable(x_instance: npt.NDArray, cf_instance: npt.NDArray, continous_indices, categorical_indices, freeze_indices) -> bool:\n",
    "    for freeze_index in freeze_indices:\n",
    "        if freeze_index in continous_indices \\\n",
    "            and not np.isclose(x_instance[freeze_index].astype('float64'), cf_instance[freeze_index].astype('float64'), atol=1e-05):\n",
    "            return False\n",
    "        if freeze_index in categorical_indices \\\n",
    "            and not np.equal(x_instance.astype('str')[freeze_index], cf_instance.astype('str')[freeze_index]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "freeze_indices = [test_dataset.columns.get_loc(c) for c in constraints['non_actionable_features']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine experiment metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_explainer_names = counterfactuals_df_all['explainer'].unique().tolist() + ['ideal_point_eucli', 'ideal_point_cheby', 'random_choice']\n",
    "\n",
    "experiment_scores = {\n",
    "    'proximity': {k: [] for k in all_explainer_names},\n",
    "    'k_feasibility_3': {k: [] for k in all_explainer_names},\n",
    "    'discriminative_power_9': {k: [] for k in all_explainer_names},\n",
    "    'sparsity': {k: [] for k in all_explainer_names},\n",
    "    'plausibility': {k: [] for k in all_explainer_names},\n",
    "    'coverage': {k: 0 for k in all_explainer_names},\n",
    "    'actionable': {k: 0 for k in all_explainer_names},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate plausibility for all counterfactuals\n",
    "for i in range(len(test_dataset)):\n",
    "    i_counterfactuals = list_of_counterfactuals_df[i]\n",
    "    i_scores = list_of_scores_df[i]\n",
    "\n",
    "    for explainer_name in all_explainer_names:\n",
    "        if 'ideal_point' in explainer_name:\n",
    "            # Get counterfactual closest to ideal point\n",
    "            iscores = i_scores[['Proximity', 'K_Feasibility(3)', 'DiscriminativePower(9)']].to_numpy()\n",
    "            \n",
    "            # Apply normalization in each feature\n",
    "            iscores = (iscores - iscores.min(axis=0)) / (iscores.max(axis=0) - iscores.min(axis=0))\n",
    "            \n",
    "            pareto_mask = get_pareto_optimal_mask(iscores, ['min', 'min', 'max'])\n",
    "            ideal_point = get_ideal_point(iscores, ['min', 'min', 'max'], pareto_mask)\n",
    "            \n",
    "            distance_metric = 'euclidean' if 'eucli' in explainer_name else 'chebyshev'\n",
    "            \n",
    "            closest_idx = get_closest_to_optimal_point(iscores, ['min', 'min', 'max'], pareto_mask, ideal_point, distance_metric)\n",
    "            #print(closest_idx)\n",
    "            _index = closest_idx\n",
    "        elif explainer_name == 'random_choice':\n",
    "            # Get random counterfactual from all counterfactuals\n",
    "            _index = np.random.permutation(i_scores.index)[0]\n",
    "        elif explainer_name not in i_scores['explainer'].unique():\n",
    "            continue\n",
    "        else:\n",
    "            #print(explainer_name)\n",
    "            # Get random counterfactual from particular explainer\n",
    "            _index = np.random.permutation(i_scores[i_counterfactuals['explainer'] == explainer_name].index)[0]\n",
    "            \n",
    "        _cf = i_counterfactuals.loc[_index]\n",
    "        _plausibility = plausibility(test_dataset, i, _cf, list_of_counterfactuals_df, ranges, continous_indices, categorical_indices)\n",
    "        experiment_scores['plausibility'][explainer_name].append(_plausibility)\n",
    "        \n",
    "        _sparsity = sparsity(test_dataset.iloc[i].to_numpy(), _cf.to_numpy(), continous_indices, categorical_indices)\n",
    "        experiment_scores['sparsity'][explainer_name].append(_sparsity)\n",
    "        \n",
    "        _score = i_scores.loc[_index]\n",
    "        experiment_scores['proximity'][explainer_name].append(_score['Proximity'])\n",
    "        experiment_scores['k_feasibility_3'][explainer_name].append(_score['K_Feasibility(3)'])\n",
    "        experiment_scores['discriminative_power_9'][explainer_name].append(_score['DiscriminativePower(9)'])\n",
    "        experiment_scores['coverage'][explainer_name] += 1\n",
    "        \n",
    "        actionable = is_actionable(test_dataset.iloc[i].to_numpy(), _cf.to_numpy(), continous_indices, categorical_indices, freeze_indices)\n",
    "        experiment_scores['actionable'][explainer_name] += int(actionable)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proximity dice: 1.93\n",
      "proximity cadex: 1.23\n",
      "proximity fimap: 6.55\n",
      "proximity wachter: 0.52\n",
      "proximity cem: 0.38\n",
      "proximity cfproto: 5.54\n",
      "proximity growing-spheres: 7.93\n",
      "proximity actionable-recourse: 0.75\n",
      "proximity face: 4.66\n",
      "proximity ideal_point_eucli: 1.49\n",
      "proximity ideal_point_cheby: 1.38\n",
      "proximity random_choice: 5.21\n",
      "k_feasibility_3 dice: 3.91\n",
      "k_feasibility_3 cadex: 3.61\n",
      "k_feasibility_3 fimap: 2.92\n",
      "k_feasibility_3 wachter: 3.31\n",
      "k_feasibility_3 cem: 3.42\n",
      "k_feasibility_3 cfproto: 4.90\n",
      "k_feasibility_3 growing-spheres: 5.81\n",
      "k_feasibility_3 actionable-recourse: 3.39\n",
      "k_feasibility_3 face: 1.72\n",
      "k_feasibility_3 ideal_point_eucli: 2.78\n",
      "k_feasibility_3 ideal_point_cheby: 2.87\n",
      "k_feasibility_3 random_choice: 3.96\n",
      "discriminative_power_9 dice: 0.45\n",
      "discriminative_power_9 cadex: 0.42\n",
      "discriminative_power_9 fimap: 0.66\n",
      "discriminative_power_9 wachter: 0.69\n",
      "discriminative_power_9 cem: 0.65\n",
      "discriminative_power_9 cfproto: 0.49\n",
      "discriminative_power_9 growing-spheres: 0.63\n",
      "discriminative_power_9 actionable-recourse: 0.42\n",
      "discriminative_power_9 face: 0.62\n",
      "discriminative_power_9 ideal_point_eucli: 0.86\n",
      "discriminative_power_9 ideal_point_cheby: 0.82\n",
      "discriminative_power_9 random_choice: 0.56\n",
      "sparsity dice: 2.17\n",
      "sparsity cadex: 2.65\n",
      "sparsity fimap: 9.57\n",
      "sparsity wachter: 3.17\n",
      "sparsity cem: 1.74\n",
      "sparsity cfproto: 7.30\n",
      "sparsity growing-spheres: 10.83\n",
      "sparsity actionable-recourse: 0.88\n",
      "sparsity face: 7.48\n",
      "sparsity ideal_point_eucli: 3.48\n",
      "sparsity ideal_point_cheby: 3.17\n",
      "sparsity random_choice: 7.57\n",
      "plausibility dice: 4.67\n",
      "plausibility cadex: 4.45\n",
      "plausibility fimap: 4.10\n",
      "plausibility wachter: 3.99\n",
      "plausibility cem: 4.18\n",
      "plausibility cfproto: 5.41\n",
      "plausibility growing-spheres: 5.77\n",
      "plausibility actionable-recourse: 4.04\n",
      "plausibility face: 4.03\n",
      "plausibility ideal_point_eucli: 3.80\n",
      "plausibility ideal_point_cheby: 3.90\n",
      "plausibility random_choice: 4.86\n",
      "coverage dice: 1.00\n",
      "coverage cadex: 1.00\n",
      "coverage fimap: 1.00\n",
      "coverage wachter: 1.00\n",
      "coverage cem: 1.00\n",
      "coverage cfproto: 1.00\n",
      "coverage growing-spheres: 1.00\n",
      "coverage actionable-recourse: 0.35\n",
      "coverage face: 1.00\n",
      "coverage ideal_point_eucli: 1.00\n",
      "coverage ideal_point_cheby: 1.00\n",
      "coverage random_choice: 1.00\n",
      "actionable dice: 1.00\n",
      "actionable cadex: 1.00\n",
      "actionable fimap: 1.00\n",
      "actionable wachter: 1.00\n",
      "actionable cem: 1.00\n",
      "actionable cfproto: 0.91\n",
      "actionable growing-spheres: 1.00\n",
      "actionable actionable-recourse: 0.35\n",
      "actionable face: 0.96\n",
      "actionable ideal_point_eucli: 1.00\n",
      "actionable ideal_point_cheby: 1.00\n",
      "actionable random_choice: 1.00\n"
     ]
    }
   ],
   "source": [
    "# average experiment scores\n",
    "for metric_name, v in experiment_scores.items():\n",
    "    for explainer_name, scores in v.items():\n",
    "        if metric_name in ['coverage', 'actionable']:\n",
    "            experiment_scores[metric_name][explainer_name] = experiment_scores[metric_name][explainer_name] / len(test_dataset)\n",
    "        else:\n",
    "            experiment_scores[metric_name][explainer_name] = np.mean(scores)\n",
    "        print(f'{metric_name} {explainer_name}: {experiment_scores[metric_name][explainer_name]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proximity</th>\n",
       "      <th>k_feasibility_3</th>\n",
       "      <th>discriminative_power_9</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>plausibility</th>\n",
       "      <th>coverage</th>\n",
       "      <th>actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dice</th>\n",
       "      <td>1.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cadex</th>\n",
       "      <td>1.23</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.65</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fimap</th>\n",
       "      <td>6.55</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.57</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wachter</th>\n",
       "      <td>0.52</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cem</th>\n",
       "      <td>0.38</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.74</td>\n",
       "      <td>4.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfproto</th>\n",
       "      <td>5.54</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.49</td>\n",
       "      <td>7.30</td>\n",
       "      <td>5.41</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing-spheres</th>\n",
       "      <td>7.93</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.83</td>\n",
       "      <td>5.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actionable-recourse</th>\n",
       "      <td>0.75</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>4.66</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.48</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal_point_eucli</th>\n",
       "      <td>1.49</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal_point_cheby</th>\n",
       "      <td>1.38</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_choice</th>\n",
       "      <td>5.21</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7.57</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proximity  k_feasibility_3  discriminative_power_9  \\\n",
       "dice                      1.93             3.91                    0.45   \n",
       "cadex                     1.23             3.61                    0.42   \n",
       "fimap                     6.55             2.92                    0.66   \n",
       "wachter                   0.52             3.31                    0.69   \n",
       "cem                       0.38             3.42                    0.65   \n",
       "cfproto                   5.54             4.90                    0.49   \n",
       "growing-spheres           7.93             5.81                    0.63   \n",
       "actionable-recourse       0.75             3.39                    0.42   \n",
       "face                      4.66             1.72                    0.62   \n",
       "ideal_point_eucli         1.49             2.78                    0.86   \n",
       "ideal_point_cheby         1.38             2.87                    0.82   \n",
       "random_choice             5.21             3.96                    0.56   \n",
       "\n",
       "                     sparsity  plausibility  coverage  actionable  \n",
       "dice                     2.17          4.67      1.00        1.00  \n",
       "cadex                    2.65          4.45      1.00        1.00  \n",
       "fimap                    9.57          4.10      1.00        1.00  \n",
       "wachter                  3.17          3.99      1.00        1.00  \n",
       "cem                      1.74          4.18      1.00        1.00  \n",
       "cfproto                  7.30          5.41      1.00        0.91  \n",
       "growing-spheres         10.83          5.77      1.00        1.00  \n",
       "actionable-recourse      0.88          4.04      0.35        0.35  \n",
       "face                     7.48          4.03      1.00        0.96  \n",
       "ideal_point_eucli        3.48          3.80      1.00        1.00  \n",
       "ideal_point_cheby        3.17          3.90      1.00        1.00  \n",
       "random_choice            7.57          4.86      1.00        1.00  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataframe from experiment scores\n",
    "experiment1_df = pd.DataFrame(experiment_scores).round(2)\n",
    "experiment1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_355e8_row0_col3, #T_355e8_row0_col5, #T_355e8_row0_col6, #T_355e8_row1_col5, #T_355e8_row1_col6, #T_355e8_row2_col5, #T_355e8_row2_col6, #T_355e8_row3_col0, #T_355e8_row3_col2, #T_355e8_row3_col4, #T_355e8_row3_col5, #T_355e8_row3_col6, #T_355e8_row4_col0, #T_355e8_row4_col3, #T_355e8_row4_col5, #T_355e8_row4_col6, #T_355e8_row5_col5, #T_355e8_row6_col5, #T_355e8_row6_col6, #T_355e8_row7_col0, #T_355e8_row7_col3, #T_355e8_row8_col1, #T_355e8_row8_col5, #T_355e8_row9_col1, #T_355e8_row9_col2, #T_355e8_row9_col4, #T_355e8_row9_col5, #T_355e8_row9_col6, #T_355e8_row10_col1, #T_355e8_row10_col2, #T_355e8_row10_col4, #T_355e8_row10_col5, #T_355e8_row10_col6, #T_355e8_row11_col5, #T_355e8_row11_col6 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_355e8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_355e8_level0_col0\" class=\"col_heading level0 col0\" >proximity</th>\n",
       "      <th id=\"T_355e8_level0_col1\" class=\"col_heading level0 col1\" >k_feasibility_3</th>\n",
       "      <th id=\"T_355e8_level0_col2\" class=\"col_heading level0 col2\" >discriminative_power_9</th>\n",
       "      <th id=\"T_355e8_level0_col3\" class=\"col_heading level0 col3\" >sparsity</th>\n",
       "      <th id=\"T_355e8_level0_col4\" class=\"col_heading level0 col4\" >plausibility</th>\n",
       "      <th id=\"T_355e8_level0_col5\" class=\"col_heading level0 col5\" >coverage</th>\n",
       "      <th id=\"T_355e8_level0_col6\" class=\"col_heading level0 col6\" >actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row0\" class=\"row_heading level0 row0\" >dice</th>\n",
       "      <td id=\"T_355e8_row0_col0\" class=\"data row0 col0\" >1.93</td>\n",
       "      <td id=\"T_355e8_row0_col1\" class=\"data row0 col1\" >3.91</td>\n",
       "      <td id=\"T_355e8_row0_col2\" class=\"data row0 col2\" >0.45</td>\n",
       "      <td id=\"T_355e8_row0_col3\" class=\"data row0 col3\" >2.17</td>\n",
       "      <td id=\"T_355e8_row0_col4\" class=\"data row0 col4\" >4.67</td>\n",
       "      <td id=\"T_355e8_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row0_col6\" class=\"data row0 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row1\" class=\"row_heading level0 row1\" >cadex</th>\n",
       "      <td id=\"T_355e8_row1_col0\" class=\"data row1 col0\" >1.23</td>\n",
       "      <td id=\"T_355e8_row1_col1\" class=\"data row1 col1\" >3.61</td>\n",
       "      <td id=\"T_355e8_row1_col2\" class=\"data row1 col2\" >0.42</td>\n",
       "      <td id=\"T_355e8_row1_col3\" class=\"data row1 col3\" >2.65</td>\n",
       "      <td id=\"T_355e8_row1_col4\" class=\"data row1 col4\" >4.45</td>\n",
       "      <td id=\"T_355e8_row1_col5\" class=\"data row1 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row1_col6\" class=\"data row1 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row2\" class=\"row_heading level0 row2\" >fimap</th>\n",
       "      <td id=\"T_355e8_row2_col0\" class=\"data row2 col0\" >6.55</td>\n",
       "      <td id=\"T_355e8_row2_col1\" class=\"data row2 col1\" >2.92</td>\n",
       "      <td id=\"T_355e8_row2_col2\" class=\"data row2 col2\" >0.66</td>\n",
       "      <td id=\"T_355e8_row2_col3\" class=\"data row2 col3\" >9.57</td>\n",
       "      <td id=\"T_355e8_row2_col4\" class=\"data row2 col4\" >4.10</td>\n",
       "      <td id=\"T_355e8_row2_col5\" class=\"data row2 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row2_col6\" class=\"data row2 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row3\" class=\"row_heading level0 row3\" >wachter</th>\n",
       "      <td id=\"T_355e8_row3_col0\" class=\"data row3 col0\" >0.52</td>\n",
       "      <td id=\"T_355e8_row3_col1\" class=\"data row3 col1\" >3.31</td>\n",
       "      <td id=\"T_355e8_row3_col2\" class=\"data row3 col2\" >0.69</td>\n",
       "      <td id=\"T_355e8_row3_col3\" class=\"data row3 col3\" >3.17</td>\n",
       "      <td id=\"T_355e8_row3_col4\" class=\"data row3 col4\" >3.99</td>\n",
       "      <td id=\"T_355e8_row3_col5\" class=\"data row3 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row3_col6\" class=\"data row3 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row4\" class=\"row_heading level0 row4\" >cem</th>\n",
       "      <td id=\"T_355e8_row4_col0\" class=\"data row4 col0\" >0.38</td>\n",
       "      <td id=\"T_355e8_row4_col1\" class=\"data row4 col1\" >3.42</td>\n",
       "      <td id=\"T_355e8_row4_col2\" class=\"data row4 col2\" >0.65</td>\n",
       "      <td id=\"T_355e8_row4_col3\" class=\"data row4 col3\" >1.74</td>\n",
       "      <td id=\"T_355e8_row4_col4\" class=\"data row4 col4\" >4.18</td>\n",
       "      <td id=\"T_355e8_row4_col5\" class=\"data row4 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row4_col6\" class=\"data row4 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row5\" class=\"row_heading level0 row5\" >cfproto</th>\n",
       "      <td id=\"T_355e8_row5_col0\" class=\"data row5 col0\" >5.54</td>\n",
       "      <td id=\"T_355e8_row5_col1\" class=\"data row5 col1\" >4.90</td>\n",
       "      <td id=\"T_355e8_row5_col2\" class=\"data row5 col2\" >0.49</td>\n",
       "      <td id=\"T_355e8_row5_col3\" class=\"data row5 col3\" >7.30</td>\n",
       "      <td id=\"T_355e8_row5_col4\" class=\"data row5 col4\" >5.41</td>\n",
       "      <td id=\"T_355e8_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row5_col6\" class=\"data row5 col6\" >0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row6\" class=\"row_heading level0 row6\" >growing-spheres</th>\n",
       "      <td id=\"T_355e8_row6_col0\" class=\"data row6 col0\" >7.93</td>\n",
       "      <td id=\"T_355e8_row6_col1\" class=\"data row6 col1\" >5.81</td>\n",
       "      <td id=\"T_355e8_row6_col2\" class=\"data row6 col2\" >0.63</td>\n",
       "      <td id=\"T_355e8_row6_col3\" class=\"data row6 col3\" >10.83</td>\n",
       "      <td id=\"T_355e8_row6_col4\" class=\"data row6 col4\" >5.77</td>\n",
       "      <td id=\"T_355e8_row6_col5\" class=\"data row6 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row7\" class=\"row_heading level0 row7\" >actionable-recourse</th>\n",
       "      <td id=\"T_355e8_row7_col0\" class=\"data row7 col0\" >0.75</td>\n",
       "      <td id=\"T_355e8_row7_col1\" class=\"data row7 col1\" >3.39</td>\n",
       "      <td id=\"T_355e8_row7_col2\" class=\"data row7 col2\" >0.42</td>\n",
       "      <td id=\"T_355e8_row7_col3\" class=\"data row7 col3\" >0.88</td>\n",
       "      <td id=\"T_355e8_row7_col4\" class=\"data row7 col4\" >4.04</td>\n",
       "      <td id=\"T_355e8_row7_col5\" class=\"data row7 col5\" >0.35</td>\n",
       "      <td id=\"T_355e8_row7_col6\" class=\"data row7 col6\" >0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row8\" class=\"row_heading level0 row8\" >face</th>\n",
       "      <td id=\"T_355e8_row8_col0\" class=\"data row8 col0\" >4.66</td>\n",
       "      <td id=\"T_355e8_row8_col1\" class=\"data row8 col1\" >1.72</td>\n",
       "      <td id=\"T_355e8_row8_col2\" class=\"data row8 col2\" >0.62</td>\n",
       "      <td id=\"T_355e8_row8_col3\" class=\"data row8 col3\" >7.48</td>\n",
       "      <td id=\"T_355e8_row8_col4\" class=\"data row8 col4\" >4.03</td>\n",
       "      <td id=\"T_355e8_row8_col5\" class=\"data row8 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row8_col6\" class=\"data row8 col6\" >0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row9\" class=\"row_heading level0 row9\" >ideal_point_eucli</th>\n",
       "      <td id=\"T_355e8_row9_col0\" class=\"data row9 col0\" >1.49</td>\n",
       "      <td id=\"T_355e8_row9_col1\" class=\"data row9 col1\" >2.78</td>\n",
       "      <td id=\"T_355e8_row9_col2\" class=\"data row9 col2\" >0.86</td>\n",
       "      <td id=\"T_355e8_row9_col3\" class=\"data row9 col3\" >3.48</td>\n",
       "      <td id=\"T_355e8_row9_col4\" class=\"data row9 col4\" >3.80</td>\n",
       "      <td id=\"T_355e8_row9_col5\" class=\"data row9 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row9_col6\" class=\"data row9 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row10\" class=\"row_heading level0 row10\" >ideal_point_cheby</th>\n",
       "      <td id=\"T_355e8_row10_col0\" class=\"data row10 col0\" >1.38</td>\n",
       "      <td id=\"T_355e8_row10_col1\" class=\"data row10 col1\" >2.87</td>\n",
       "      <td id=\"T_355e8_row10_col2\" class=\"data row10 col2\" >0.82</td>\n",
       "      <td id=\"T_355e8_row10_col3\" class=\"data row10 col3\" >3.17</td>\n",
       "      <td id=\"T_355e8_row10_col4\" class=\"data row10 col4\" >3.90</td>\n",
       "      <td id=\"T_355e8_row10_col5\" class=\"data row10 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row10_col6\" class=\"data row10 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_355e8_level0_row11\" class=\"row_heading level0 row11\" >random_choice</th>\n",
       "      <td id=\"T_355e8_row11_col0\" class=\"data row11 col0\" >5.21</td>\n",
       "      <td id=\"T_355e8_row11_col1\" class=\"data row11 col1\" >3.96</td>\n",
       "      <td id=\"T_355e8_row11_col2\" class=\"data row11 col2\" >0.56</td>\n",
       "      <td id=\"T_355e8_row11_col3\" class=\"data row11 col3\" >7.57</td>\n",
       "      <td id=\"T_355e8_row11_col4\" class=\"data row11 col4\" >4.86</td>\n",
       "      <td id=\"T_355e8_row11_col5\" class=\"data row11 col5\" >1.00</td>\n",
       "      <td id=\"T_355e8_row11_col6\" class=\"data row11 col6\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb3a4094610>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_metric = ['discriminative_power_9', 'coverage', 'actionable']\n",
    "\n",
    "def highlight_top3(s):\n",
    "    #print(s)\n",
    "    if s.name in max_metric:\n",
    "        top = sorted(s, reverse=True)[:3]\n",
    "    else:\n",
    "        top = sorted(s)[:3]\n",
    "    return ['font-weight: bold' if v  in top else '' for v in s]\n",
    "\n",
    "# bold top 3 in each metric\n",
    "res = experiment1_df.style.apply(highlight_top3, axis=0)\n",
    "# Round to 2 decimals\n",
    "res = res.format(precision=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      " & proximity & k_feasibility_3 & discriminative_power_9 & sparsity & plausibility & coverage & actionable \\\\\n",
      "dice & 1.93 & 3.91 & 0.45 & \\font-weightbold 2.17 & 4.67 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "cadex & 1.23 & 3.61 & 0.42 & 2.65 & 4.45 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "fimap & 6.55 & 2.92 & 0.66 & 9.57 & 4.10 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "wachter & \\font-weightbold 0.52 & 3.31 & \\font-weightbold 0.69 & 3.17 & \\font-weightbold 3.99 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "cem & \\font-weightbold 0.38 & 3.42 & 0.65 & \\font-weightbold 1.74 & 4.18 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "cfproto & 5.54 & 4.90 & 0.49 & 7.30 & 5.41 & \\font-weightbold 1.00 & 0.91 \\\\\n",
      "growing-spheres & 7.93 & 5.81 & 0.63 & 10.83 & 5.77 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "actionable-recourse & \\font-weightbold 0.75 & 3.39 & 0.42 & \\font-weightbold 0.88 & 4.04 & 0.35 & 0.35 \\\\\n",
      "face & 4.66 & \\font-weightbold 1.72 & 0.62 & 7.48 & 4.03 & \\font-weightbold 1.00 & 0.96 \\\\\n",
      "ideal_point_eucli & 1.49 & \\font-weightbold 2.78 & \\font-weightbold 0.86 & 3.48 & \\font-weightbold 3.80 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "ideal_point_cheby & 1.38 & \\font-weightbold 2.87 & \\font-weightbold 0.82 & 3.17 & \\font-weightbold 3.90 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "random_choice & 5.21 & 3.96 & 0.56 & 7.57 & 4.86 & \\font-weightbold 1.00 & \\font-weightbold 1.00 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas dataframe to latex table\n",
    "print(res.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
