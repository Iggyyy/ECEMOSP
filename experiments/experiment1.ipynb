{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from experiment_utils import load_data, get_closest_to_optimal_point, get_pareto_optimal_mask, get_ideal_point\n",
    "\n",
    "dataset = 'adult'\n",
    "date = '2023-03-12'\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'experiments', date, 'scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered scores for 195 instances\n"
     ]
    }
   ],
   "source": [
    "# Load scores\n",
    "list_of_scores_df , scores_df_all, scores_test_set_indices = load_data('scores', date, dataset)\n",
    "print(f'Gathered scores for {len(list_of_scores_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered valid_scores for 195 instances\n"
     ]
    }
   ],
   "source": [
    "# Load valid_scores\n",
    "list_of_valid_scores_df , valid_scores_df_all, valid_scores_test_set_indices = load_data('valid_scores', date, dataset)\n",
    "print(f'Gathered valid_scores for {len(list_of_valid_scores_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered counterfactuals for 195 instances\n"
     ]
    }
   ],
   "source": [
    "# Load counterfactuals\n",
    "list_of_counterfactuals_df , counterfactuals_df_all, cf_test_set_indices = load_data('counterfactuals', date, dataset)\n",
    "print(f'Gathered counterfactuals for {len(list_of_counterfactuals_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered valid_counterfactuals for 195 instances\n"
     ]
    }
   ],
   "source": [
    "# Load valid_counterfactuals\n",
    "list_of_valid_counterfactuals_df , valid_counterfactuals_df_all, valid_cf_test_set_indices = load_data('valid_counterfactuals', date, dataset)\n",
    "print(f'Gathered valid_counterfactuals for {len(list_of_valid_counterfactuals_df)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data for 195 instances\n"
     ]
    }
   ],
   "source": [
    "# Load test data - original x instances\n",
    "if 'experiments' in os.getcwd():\n",
    "    test_data_path = os.path.join(os.path.pardir, 'data', f'{dataset}_test.csv')\n",
    "else:\n",
    "    test_data_path = os.path.join(os.getcwd(), 'data', f'{dataset}_test.csv')\n",
    "\n",
    "\n",
    "test_dataset = pd.read_csv(test_data_path).iloc[scores_test_set_indices]\n",
    "print(f'Loaded test data for {len(test_dataset)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded constraints for: adult\n"
     ]
    }
   ],
   "source": [
    "# Load constraints for the dataset\n",
    "with open(os.path.join(os.path.pardir, 'data', f'{dataset}_constraints.json'), 'r') as f:\n",
    "    constraints = json.load(f)\n",
    "print(f'Loaded constraints for: {constraints[\"dataset_shortname\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scores_test_set_indices == cf_test_set_indices\n",
    "assert len(list_of_scores_df) == len(list_of_counterfactuals_df) == len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continous indices: [0, 1, 2, 3, 4]\n",
      "Categorical indices: [5, 6, 7, 8, 9, 10]\n",
      "Ranges: [   73    14 15024  2415    71]\n",
      "Test plausibility: 1.75\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_ranges(test_data: pd.DataFrame, constraints: dict) -> npt.NDArray:\n",
    "    '''\n",
    "    Get ranges for continous variables.\n",
    "    '''\n",
    "    mins = test_data[constraints['continuous_features_nonsplit']].to_numpy().min(axis=0)\n",
    "    maxes = test_data[constraints['continuous_features_nonsplit']].to_numpy().max(axis=0)\n",
    "    feature_ranges = maxes - mins\n",
    "    return feature_ranges\n",
    "\n",
    "\n",
    "def heom(x: npt.NDArray, y: npt.NDArray, ranges: npt.NDArray, continous_indices: npt.NDArray, categorical_indices: npt.NDArray) -> float:\n",
    "    '''\n",
    "    Calculate HEOM distance between x and y. \n",
    "    X and Y should not be normalized. \n",
    "    X should be (n, m) dimensional.\n",
    "    Y should be 1-D array.\n",
    "    Ranges is max-min on each continous variables (order matters). \n",
    "    '''\n",
    "    distance = np.zeros(x.shape[0])\n",
    "\n",
    "    # Continous |x-y| / range\n",
    "    distance += np.sum(np.abs(x[:, continous_indices].astype('float64') - y[continous_indices].astype('float64')) / ranges, axis=1)\n",
    "\n",
    "    # Categorical - overlap\n",
    "    distance += np.sum(~np.equal(x[:, categorical_indices], y[categorical_indices]), axis=1)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def plausibility(test_data: pd.DataFrame, \n",
    "                 x_index: int, \n",
    "                 counterfactual: pd.DataFrame | pd.Series, \n",
    "                 list_of_counterfactuals_df: List[pd.DataFrame], \n",
    "                 ranges: npt.NDArray, \n",
    "                 continous_indices: npt.NDArray | List[float], \n",
    "                 categorical_indices: npt.NDArray | List[float]\n",
    "                 ):\n",
    "    # Find closest instance to original_x in test_data\n",
    "    n = len(test_data)\n",
    "    x = test_data.iloc[0:n+1].to_numpy()\n",
    "    y = test_data.iloc[x_index].to_numpy()\n",
    "\n",
    "    all_distances = heom(x, y, ranges, continous_indices, categorical_indices)\n",
    "    # find closest instance to original_x in test_data\n",
    "    sorting_indices = np.argsort(all_distances)\n",
    "    # we do not take 0 because it is the same instance as original_x\n",
    "    closest_index = np.array(list(zip(range(n), all_distances)))[sorting_indices][1][0].astype(int)\n",
    "    # counterfactuals of closest x' to x\n",
    "    closest_counterfactuals = list_of_counterfactuals_df[closest_index].to_numpy()\n",
    "    \n",
    "    # x_counterfactuals = list_of_counterfactuals_df[x_index].to_numpy()\n",
    "    # # calculate all pairs of distances between counterfactuals from x and x'\n",
    "    # sum_of_distances = .0\n",
    "    # for x_cf in x_counterfactuals:\n",
    "    #     mean_distance = np.mean(heom(closest_counterfactuals, x_cf, ranges, continous_indices, categorical_indices))\n",
    "    #     sum_of_distances += mean_distance\n",
    "    # return sum_of_distances / len(x_counterfactuals)\n",
    "    \n",
    "    plausibility_score = np.min(heom(closest_counterfactuals, counterfactual.to_numpy(), ranges, continous_indices, categorical_indices))\n",
    "    return plausibility_score\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "continous_indices = [test_dataset.columns.get_loc(c) for c in constraints['continuous_features_nonsplit']]\n",
    "categorical_indices = [test_dataset.columns.get_loc(c) for c in constraints['categorical_features_nonsplit']]\n",
    "ranges = get_ranges(test_dataset, constraints)\n",
    "\n",
    "print(f'Continous indices: {continous_indices}')\n",
    "print(f'Categorical indices: {categorical_indices}')\n",
    "print(f'Ranges: {ranges}')\n",
    "\n",
    "test_plaus = plausibility(test_dataset, 0, list_of_counterfactuals_df[0].iloc[0], list_of_counterfactuals_df, ranges, continous_indices, categorical_indices)\n",
    "# Calculate example plausibility score\n",
    "print(f'Test plausibility: {test_plaus:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(x_instance: npt.NDArray, cf_instance: npt.NDArray, continous_indices, categorical_indices) -> int:\n",
    "    _sparsity = 0\n",
    "    \n",
    "    # Continous\n",
    "    _sparsity += np.sum(~np.isclose(x_instance[continous_indices].astype('float64'), cf_instance[continous_indices].astype('float64'), atol=1e-05))\n",
    "    \n",
    "    # Categorical\n",
    "    _sparsity += np.sum(~np.equal(x_instance[categorical_indices].astype('str'), cf_instance[categorical_indices].astype('str')))\n",
    "    \n",
    "    return _sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_actionable(x_instance: npt.NDArray, cf_instance: npt.NDArray, continous_indices, categorical_indices, freeze_indices) -> bool:\n",
    "    for freeze_index in freeze_indices:\n",
    "        if freeze_index in continous_indices \\\n",
    "            and not np.isclose(x_instance[freeze_index].astype('float64'), cf_instance[freeze_index].astype('float64'), atol=1e-05):\n",
    "            return False\n",
    "        if freeze_index in categorical_indices \\\n",
    "            and not np.equal(x_instance.astype('str')[freeze_index], cf_instance.astype('str')[freeze_index]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "freeze_indices = [test_dataset.columns.get_loc(c) for c in constraints['non_actionable_features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actionable_indices(x_instance: pd.DataFrame | pd.Series, cf_instances: pd.DataFrame, continous_indices, categorical_indices, freeze_indices) -> npt.NDArray:\n",
    "    actionability = []\n",
    "    for _, _cf in cf_instances.iterrows():\n",
    "        actionability.append(is_actionable(x_instance.to_numpy(), _cf.to_numpy(), continous_indices, categorical_indices, freeze_indices))\n",
    "    return cf_instances[actionability].index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine experiment metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_explainer_names = counterfactuals_df_all['explainer'].unique().tolist() + ['ideal_point_eucli', 'ideal_point_cheby', 'random_choice']\n",
    "\n",
    "experiment_scores = {\n",
    "    'proximity': {k: [] for k in all_explainer_names},\n",
    "    'k_feasibility_3': {k: [] for k in all_explainer_names},\n",
    "    'discriminative_power_9': {k: [] for k in all_explainer_names},\n",
    "    'sparsity': {k: [] for k in all_explainer_names},\n",
    "    'plausibility': {k: [] for k in all_explainer_names},\n",
    "    'coverage': {k: 0 for k in all_explainer_names},\n",
    "    'actionable': {k: 0 for k in all_explainer_names},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate plausibility for all counterfactuals\n",
    "for i in range(len(test_dataset)):\n",
    "    for explainer_name in all_explainer_names:\n",
    "        i_counterfactuals = list_of_counterfactuals_df[i]\n",
    "        i_scores = list_of_scores_df[i]\n",
    "        \n",
    "        if 'ideal_point' in explainer_name:\n",
    "            \n",
    "            # Filter counterfactuals to include only actionable\n",
    "            actionable_indices = get_actionable_indices(test_dataset.iloc[i], i_counterfactuals, continous_indices, categorical_indices, freeze_indices)\n",
    "            \n",
    "            i_counterfactuals = i_counterfactuals.iloc[actionable_indices]\n",
    "            i_scores = i_scores.iloc[actionable_indices]\n",
    "            \n",
    "            # Get counterfactual closest to ideal point\n",
    "            iscores = i_scores[['Proximity', 'K_Feasibility(3)', 'DiscriminativePower(9)']].to_numpy()\n",
    "            \n",
    "            # Apply normalization in each feature\n",
    "            iscores = (iscores - iscores.min(axis=0)) / (iscores.max(axis=0) - iscores.min(axis=0))\n",
    "            \n",
    "            pareto_mask = get_pareto_optimal_mask(iscores, ['min', 'min', 'max'])\n",
    "            ideal_point = get_ideal_point(iscores, ['min', 'min', 'max'], pareto_mask)\n",
    "            \n",
    "            distance_metric = 'euclidean' if 'eucli' in explainer_name else 'chebyshev'\n",
    "            \n",
    "            closest_idx = get_closest_to_optimal_point(iscores, ['min', 'min', 'max'], pareto_mask, ideal_point, distance_metric)\n",
    "            #print(closest_idx)\n",
    "            _index = closest_idx\n",
    "        elif explainer_name == 'random_choice':\n",
    "            # Get random counterfactual from all counterfactuals\n",
    "            _index = np.random.permutation(i_scores.index)[0]\n",
    "        elif explainer_name not in i_scores['explainer'].unique():\n",
    "            continue\n",
    "        else:\n",
    "            #print(explainer_name)\n",
    "            # Get random counterfactual from particular explainer\n",
    "            _index = np.random.permutation(i_scores[i_counterfactuals['explainer'] == explainer_name].index)[0]\n",
    "            \n",
    "        _cf = i_counterfactuals.iloc[_index]\n",
    "        _plausibility = plausibility(test_dataset, i, _cf, list_of_counterfactuals_df, ranges, continous_indices, categorical_indices)\n",
    "        experiment_scores['plausibility'][explainer_name].append(_plausibility)\n",
    "        \n",
    "        _sparsity = sparsity(test_dataset.iloc[i].to_numpy(), _cf.to_numpy(), continous_indices, categorical_indices)\n",
    "        experiment_scores['sparsity'][explainer_name].append(_sparsity)\n",
    "        \n",
    "        _score = i_scores.iloc[_index]\n",
    "        experiment_scores['proximity'][explainer_name].append(_score['Proximity'])\n",
    "        experiment_scores['k_feasibility_3'][explainer_name].append(_score['K_Feasibility(3)'])\n",
    "        experiment_scores['discriminative_power_9'][explainer_name].append(_score['DiscriminativePower(9)'])\n",
    "        experiment_scores['coverage'][explainer_name] += 1\n",
    "        \n",
    "        actionable = is_actionable(test_dataset.iloc[i].to_numpy(), _cf.to_numpy(), continous_indices, categorical_indices, freeze_indices)\n",
    "        experiment_scores['actionable'][explainer_name] += int(actionable)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proximity dice: 1.12\n",
      "proximity fimap: 2.03\n",
      "proximity cadex: 0.20\n",
      "proximity wachter: 0.69\n",
      "proximity cem: 0.13\n",
      "proximity cfproto: 2.03\n",
      "proximity growing-spheres: 2.70\n",
      "proximity face: 1.14\n",
      "proximity actionable-recourse: 0.74\n",
      "proximity ideal_point_eucli: 0.35\n",
      "proximity ideal_point_cheby: 0.35\n",
      "proximity random_choice: 1.49\n",
      "k_feasibility_3 dice: 0.86\n",
      "k_feasibility_3 fimap: 0.34\n",
      "k_feasibility_3 cadex: 0.30\n",
      "k_feasibility_3 wachter: 0.42\n",
      "k_feasibility_3 cem: 0.31\n",
      "k_feasibility_3 cfproto: 1.47\n",
      "k_feasibility_3 growing-spheres: 1.37\n",
      "k_feasibility_3 face: 0.07\n",
      "k_feasibility_3 actionable-recourse: 0.74\n",
      "k_feasibility_3 ideal_point_eucli: 0.24\n",
      "k_feasibility_3 ideal_point_cheby: 0.25\n",
      "k_feasibility_3 random_choice: 0.71\n",
      "discriminative_power_9 dice: 0.36\n",
      "discriminative_power_9 fimap: 0.64\n",
      "discriminative_power_9 cadex: 0.17\n",
      "discriminative_power_9 wachter: 0.65\n",
      "discriminative_power_9 cem: 0.41\n",
      "discriminative_power_9 cfproto: 0.31\n",
      "discriminative_power_9 growing-spheres: 0.48\n",
      "discriminative_power_9 face: 0.70\n",
      "discriminative_power_9 actionable-recourse: 0.67\n",
      "discriminative_power_9 ideal_point_eucli: 0.97\n",
      "discriminative_power_9 ideal_point_cheby: 0.95\n",
      "discriminative_power_9 random_choice: 0.50\n",
      "sparsity dice: 1.70\n",
      "sparsity fimap: 5.65\n",
      "sparsity cadex: 2.16\n",
      "sparsity wachter: 3.39\n",
      "sparsity cem: 1.13\n",
      "sparsity cfproto: 2.96\n",
      "sparsity growing-spheres: 6.17\n",
      "sparsity face: 3.72\n",
      "sparsity actionable-recourse: 1.81\n",
      "sparsity ideal_point_eucli: 2.56\n",
      "sparsity ideal_point_cheby: 2.58\n",
      "sparsity random_choice: 3.58\n",
      "plausibility dice: 1.67\n",
      "plausibility fimap: 1.33\n",
      "plausibility cadex: 0.81\n",
      "plausibility wachter: 1.00\n",
      "plausibility cem: 0.87\n",
      "plausibility cfproto: 2.15\n",
      "plausibility growing-spheres: 1.99\n",
      "plausibility face: 0.62\n",
      "plausibility actionable-recourse: 1.13\n",
      "plausibility ideal_point_eucli: 0.77\n",
      "plausibility ideal_point_cheby: 0.80\n",
      "plausibility random_choice: 1.41\n",
      "coverage dice: 1.00\n",
      "coverage fimap: 1.00\n",
      "coverage cadex: 0.99\n",
      "coverage wachter: 0.96\n",
      "coverage cem: 1.00\n",
      "coverage cfproto: 0.99\n",
      "coverage growing-spheres: 1.00\n",
      "coverage face: 1.00\n",
      "coverage actionable-recourse: 0.38\n",
      "coverage ideal_point_eucli: 1.00\n",
      "coverage ideal_point_cheby: 1.00\n",
      "coverage random_choice: 1.00\n",
      "actionable dice: 1.00\n",
      "actionable fimap: 1.00\n",
      "actionable cadex: 0.99\n",
      "actionable wachter: 0.96\n",
      "actionable cem: 1.00\n",
      "actionable cfproto: 0.09\n",
      "actionable growing-spheres: 1.00\n",
      "actionable face: 0.83\n",
      "actionable actionable-recourse: 0.38\n",
      "actionable ideal_point_eucli: 1.00\n",
      "actionable ideal_point_cheby: 1.00\n",
      "actionable random_choice: 0.90\n"
     ]
    }
   ],
   "source": [
    "# average experiment scores\n",
    "for metric_name, v in experiment_scores.items():\n",
    "    for explainer_name, scores in v.items():\n",
    "        if metric_name in ['coverage', 'actionable']:\n",
    "            experiment_scores[metric_name][explainer_name] = experiment_scores[metric_name][explainer_name] / len(test_dataset)\n",
    "        else:\n",
    "            experiment_scores[metric_name][explainer_name] = np.mean(scores)\n",
    "        print(f'{metric_name} {explainer_name}: {experiment_scores[metric_name][explainer_name]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proximity</th>\n",
       "      <th>k_feasibility_3</th>\n",
       "      <th>discriminative_power_9</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>plausibility</th>\n",
       "      <th>coverage</th>\n",
       "      <th>actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dice</th>\n",
       "      <td>1.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fimap</th>\n",
       "      <td>2.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cadex</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wachter</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cem</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfproto</th>\n",
       "      <td>2.03</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing-spheres</th>\n",
       "      <td>2.70</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>6.17</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>1.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actionable-recourse</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal_point_eucli</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal_point_cheby</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_choice</th>\n",
       "      <td>1.49</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proximity  k_feasibility_3  discriminative_power_9  \\\n",
       "dice                      1.12             0.86                    0.36   \n",
       "fimap                     2.03             0.34                    0.64   \n",
       "cadex                     0.20             0.30                    0.17   \n",
       "wachter                   0.69             0.42                    0.65   \n",
       "cem                       0.13             0.31                    0.41   \n",
       "cfproto                   2.03             1.47                    0.31   \n",
       "growing-spheres           2.70             1.37                    0.48   \n",
       "face                      1.14             0.07                    0.70   \n",
       "actionable-recourse       0.74             0.74                    0.67   \n",
       "ideal_point_eucli         0.35             0.24                    0.97   \n",
       "ideal_point_cheby         0.35             0.25                    0.95   \n",
       "random_choice             1.49             0.71                    0.50   \n",
       "\n",
       "                     sparsity  plausibility  coverage  actionable  \n",
       "dice                     1.70          1.67      1.00        1.00  \n",
       "fimap                    5.65          1.33      1.00        1.00  \n",
       "cadex                    2.16          0.81      0.99        0.99  \n",
       "wachter                  3.39          1.00      0.96        0.96  \n",
       "cem                      1.13          0.87      1.00        1.00  \n",
       "cfproto                  2.96          2.15      0.99        0.09  \n",
       "growing-spheres          6.17          1.99      1.00        1.00  \n",
       "face                     3.72          0.62      1.00        0.83  \n",
       "actionable-recourse      1.81          1.13      0.38        0.38  \n",
       "ideal_point_eucli        2.56          0.77      1.00        1.00  \n",
       "ideal_point_cheby        2.58          0.80      1.00        1.00  \n",
       "random_choice            3.58          1.41      1.00        0.90  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataframe from experiment scores\n",
    "experiment1_df = pd.DataFrame(experiment_scores).round(2)\n",
    "experiment1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_445f3_row0_col3, #T_445f3_row0_col5, #T_445f3_row0_col6, #T_445f3_row1_col5, #T_445f3_row1_col6, #T_445f3_row2_col0, #T_445f3_row4_col0, #T_445f3_row4_col3, #T_445f3_row4_col5, #T_445f3_row4_col6, #T_445f3_row6_col5, #T_445f3_row6_col6, #T_445f3_row7_col1, #T_445f3_row7_col2, #T_445f3_row7_col4, #T_445f3_row7_col5, #T_445f3_row8_col3, #T_445f3_row9_col0, #T_445f3_row9_col1, #T_445f3_row9_col2, #T_445f3_row9_col4, #T_445f3_row9_col5, #T_445f3_row9_col6, #T_445f3_row10_col0, #T_445f3_row10_col1, #T_445f3_row10_col2, #T_445f3_row10_col4, #T_445f3_row10_col5, #T_445f3_row10_col6, #T_445f3_row11_col5 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_445f3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_445f3_level0_col0\" class=\"col_heading level0 col0\" >proximity</th>\n",
       "      <th id=\"T_445f3_level0_col1\" class=\"col_heading level0 col1\" >k_feasibility_3</th>\n",
       "      <th id=\"T_445f3_level0_col2\" class=\"col_heading level0 col2\" >discriminative_power_9</th>\n",
       "      <th id=\"T_445f3_level0_col3\" class=\"col_heading level0 col3\" >sparsity</th>\n",
       "      <th id=\"T_445f3_level0_col4\" class=\"col_heading level0 col4\" >plausibility</th>\n",
       "      <th id=\"T_445f3_level0_col5\" class=\"col_heading level0 col5\" >coverage</th>\n",
       "      <th id=\"T_445f3_level0_col6\" class=\"col_heading level0 col6\" >actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row0\" class=\"row_heading level0 row0\" >dice</th>\n",
       "      <td id=\"T_445f3_row0_col0\" class=\"data row0 col0\" >1.12</td>\n",
       "      <td id=\"T_445f3_row0_col1\" class=\"data row0 col1\" >0.86</td>\n",
       "      <td id=\"T_445f3_row0_col2\" class=\"data row0 col2\" >0.36</td>\n",
       "      <td id=\"T_445f3_row0_col3\" class=\"data row0 col3\" >1.70</td>\n",
       "      <td id=\"T_445f3_row0_col4\" class=\"data row0 col4\" >1.67</td>\n",
       "      <td id=\"T_445f3_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row0_col6\" class=\"data row0 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row1\" class=\"row_heading level0 row1\" >fimap</th>\n",
       "      <td id=\"T_445f3_row1_col0\" class=\"data row1 col0\" >2.03</td>\n",
       "      <td id=\"T_445f3_row1_col1\" class=\"data row1 col1\" >0.34</td>\n",
       "      <td id=\"T_445f3_row1_col2\" class=\"data row1 col2\" >0.64</td>\n",
       "      <td id=\"T_445f3_row1_col3\" class=\"data row1 col3\" >5.65</td>\n",
       "      <td id=\"T_445f3_row1_col4\" class=\"data row1 col4\" >1.33</td>\n",
       "      <td id=\"T_445f3_row1_col5\" class=\"data row1 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row1_col6\" class=\"data row1 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row2\" class=\"row_heading level0 row2\" >cadex</th>\n",
       "      <td id=\"T_445f3_row2_col0\" class=\"data row2 col0\" >0.20</td>\n",
       "      <td id=\"T_445f3_row2_col1\" class=\"data row2 col1\" >0.30</td>\n",
       "      <td id=\"T_445f3_row2_col2\" class=\"data row2 col2\" >0.17</td>\n",
       "      <td id=\"T_445f3_row2_col3\" class=\"data row2 col3\" >2.16</td>\n",
       "      <td id=\"T_445f3_row2_col4\" class=\"data row2 col4\" >0.81</td>\n",
       "      <td id=\"T_445f3_row2_col5\" class=\"data row2 col5\" >0.99</td>\n",
       "      <td id=\"T_445f3_row2_col6\" class=\"data row2 col6\" >0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row3\" class=\"row_heading level0 row3\" >wachter</th>\n",
       "      <td id=\"T_445f3_row3_col0\" class=\"data row3 col0\" >0.69</td>\n",
       "      <td id=\"T_445f3_row3_col1\" class=\"data row3 col1\" >0.42</td>\n",
       "      <td id=\"T_445f3_row3_col2\" class=\"data row3 col2\" >0.65</td>\n",
       "      <td id=\"T_445f3_row3_col3\" class=\"data row3 col3\" >3.39</td>\n",
       "      <td id=\"T_445f3_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_445f3_row3_col5\" class=\"data row3 col5\" >0.96</td>\n",
       "      <td id=\"T_445f3_row3_col6\" class=\"data row3 col6\" >0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row4\" class=\"row_heading level0 row4\" >cem</th>\n",
       "      <td id=\"T_445f3_row4_col0\" class=\"data row4 col0\" >0.13</td>\n",
       "      <td id=\"T_445f3_row4_col1\" class=\"data row4 col1\" >0.31</td>\n",
       "      <td id=\"T_445f3_row4_col2\" class=\"data row4 col2\" >0.41</td>\n",
       "      <td id=\"T_445f3_row4_col3\" class=\"data row4 col3\" >1.13</td>\n",
       "      <td id=\"T_445f3_row4_col4\" class=\"data row4 col4\" >0.87</td>\n",
       "      <td id=\"T_445f3_row4_col5\" class=\"data row4 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row4_col6\" class=\"data row4 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row5\" class=\"row_heading level0 row5\" >cfproto</th>\n",
       "      <td id=\"T_445f3_row5_col0\" class=\"data row5 col0\" >2.03</td>\n",
       "      <td id=\"T_445f3_row5_col1\" class=\"data row5 col1\" >1.47</td>\n",
       "      <td id=\"T_445f3_row5_col2\" class=\"data row5 col2\" >0.31</td>\n",
       "      <td id=\"T_445f3_row5_col3\" class=\"data row5 col3\" >2.96</td>\n",
       "      <td id=\"T_445f3_row5_col4\" class=\"data row5 col4\" >2.15</td>\n",
       "      <td id=\"T_445f3_row5_col5\" class=\"data row5 col5\" >0.99</td>\n",
       "      <td id=\"T_445f3_row5_col6\" class=\"data row5 col6\" >0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row6\" class=\"row_heading level0 row6\" >growing-spheres</th>\n",
       "      <td id=\"T_445f3_row6_col0\" class=\"data row6 col0\" >2.70</td>\n",
       "      <td id=\"T_445f3_row6_col1\" class=\"data row6 col1\" >1.37</td>\n",
       "      <td id=\"T_445f3_row6_col2\" class=\"data row6 col2\" >0.48</td>\n",
       "      <td id=\"T_445f3_row6_col3\" class=\"data row6 col3\" >6.17</td>\n",
       "      <td id=\"T_445f3_row6_col4\" class=\"data row6 col4\" >1.99</td>\n",
       "      <td id=\"T_445f3_row6_col5\" class=\"data row6 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row7\" class=\"row_heading level0 row7\" >face</th>\n",
       "      <td id=\"T_445f3_row7_col0\" class=\"data row7 col0\" >1.14</td>\n",
       "      <td id=\"T_445f3_row7_col1\" class=\"data row7 col1\" >0.07</td>\n",
       "      <td id=\"T_445f3_row7_col2\" class=\"data row7 col2\" >0.70</td>\n",
       "      <td id=\"T_445f3_row7_col3\" class=\"data row7 col3\" >3.72</td>\n",
       "      <td id=\"T_445f3_row7_col4\" class=\"data row7 col4\" >0.62</td>\n",
       "      <td id=\"T_445f3_row7_col5\" class=\"data row7 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row7_col6\" class=\"data row7 col6\" >0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row8\" class=\"row_heading level0 row8\" >actionable-recourse</th>\n",
       "      <td id=\"T_445f3_row8_col0\" class=\"data row8 col0\" >0.74</td>\n",
       "      <td id=\"T_445f3_row8_col1\" class=\"data row8 col1\" >0.74</td>\n",
       "      <td id=\"T_445f3_row8_col2\" class=\"data row8 col2\" >0.67</td>\n",
       "      <td id=\"T_445f3_row8_col3\" class=\"data row8 col3\" >1.81</td>\n",
       "      <td id=\"T_445f3_row8_col4\" class=\"data row8 col4\" >1.13</td>\n",
       "      <td id=\"T_445f3_row8_col5\" class=\"data row8 col5\" >0.38</td>\n",
       "      <td id=\"T_445f3_row8_col6\" class=\"data row8 col6\" >0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row9\" class=\"row_heading level0 row9\" >ideal_point_eucli</th>\n",
       "      <td id=\"T_445f3_row9_col0\" class=\"data row9 col0\" >0.35</td>\n",
       "      <td id=\"T_445f3_row9_col1\" class=\"data row9 col1\" >0.24</td>\n",
       "      <td id=\"T_445f3_row9_col2\" class=\"data row9 col2\" >0.97</td>\n",
       "      <td id=\"T_445f3_row9_col3\" class=\"data row9 col3\" >2.56</td>\n",
       "      <td id=\"T_445f3_row9_col4\" class=\"data row9 col4\" >0.77</td>\n",
       "      <td id=\"T_445f3_row9_col5\" class=\"data row9 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row9_col6\" class=\"data row9 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row10\" class=\"row_heading level0 row10\" >ideal_point_cheby</th>\n",
       "      <td id=\"T_445f3_row10_col0\" class=\"data row10 col0\" >0.35</td>\n",
       "      <td id=\"T_445f3_row10_col1\" class=\"data row10 col1\" >0.25</td>\n",
       "      <td id=\"T_445f3_row10_col2\" class=\"data row10 col2\" >0.95</td>\n",
       "      <td id=\"T_445f3_row10_col3\" class=\"data row10 col3\" >2.58</td>\n",
       "      <td id=\"T_445f3_row10_col4\" class=\"data row10 col4\" >0.80</td>\n",
       "      <td id=\"T_445f3_row10_col5\" class=\"data row10 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row10_col6\" class=\"data row10 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_445f3_level0_row11\" class=\"row_heading level0 row11\" >random_choice</th>\n",
       "      <td id=\"T_445f3_row11_col0\" class=\"data row11 col0\" >1.49</td>\n",
       "      <td id=\"T_445f3_row11_col1\" class=\"data row11 col1\" >0.71</td>\n",
       "      <td id=\"T_445f3_row11_col2\" class=\"data row11 col2\" >0.50</td>\n",
       "      <td id=\"T_445f3_row11_col3\" class=\"data row11 col3\" >3.58</td>\n",
       "      <td id=\"T_445f3_row11_col4\" class=\"data row11 col4\" >1.41</td>\n",
       "      <td id=\"T_445f3_row11_col5\" class=\"data row11 col5\" >1.00</td>\n",
       "      <td id=\"T_445f3_row11_col6\" class=\"data row11 col6\" >0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24132fa9480>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_metric = ['discriminative_power_9', 'coverage', 'actionable']\n",
    "\n",
    "def highlight_top3(s):\n",
    "    #print(s)\n",
    "    if s.name in max_metric:\n",
    "        top = sorted(s, reverse=True)[:3]\n",
    "    else:\n",
    "        top = sorted(s)[:3]\n",
    "    return ['font-weight: bold' if v  in top else '' for v in s]\n",
    "\n",
    "# bold top 3 in each metric\n",
    "res = experiment1_df.style.apply(highlight_top3, axis=0)\n",
    "# Round to 2 decimals\n",
    "res = res.format(precision=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr} \\hline\n",
      " & prox $\\downarrow$& feas-3 $\\downarrow$& discrpow-9 $\\uparrow$& spars $\\downarrow$& plausib $\\downarrow$& cover $\\uparrow$& actionab $\\uparrow$\\\\ \\hline\n",
      "dice & 1.12 & 0.86 & 0.36 & \\bfseries 1.70 & 1.67 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "fimap & 2.03 & 0.34 & 0.64 & 5.65 & 1.33 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "cadex & \\bfseries 0.20 & 0.30 & 0.17 & 2.16 & 0.81 & 0.99 & 0.99 \\\\ \\hline\n",
      "wachter & 0.69 & 0.42 & 0.65 & 3.39 & 1.00 & 0.96 & 0.96 \\\\ \\hline\n",
      "cem & \\bfseries 0.13 & 0.31 & 0.41 & \\bfseries 1.13 & 0.87 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "cfproto & 2.03 & 1.47 & 0.31 & 2.96 & 2.15 & 0.99 & 0.09 \\\\ \\hline\n",
      "growing-spheres & 2.70 & 1.37 & 0.48 & 6.17 & 1.99 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "face & 1.14 & \\bfseries 0.07 & \\bfseries 0.70 & 3.72 & \\bfseries 0.62 & \\bfseries 1.00 & 0.83 \\\\ \\hline\n",
      "actionable-recourse & 0.74 & 0.74 & 0.67 & \\bfseries 1.81 & 1.13 & 0.38 & 0.38 \\\\ \\hline\n",
      "\\bfseries ideal-point-eucli & \\bfseries 0.35 & \\bfseries 0.24 & \\bfseries 0.97 & 2.56 & \\bfseries 0.77 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "\\bfseries ideal-point-cheby & \\bfseries 0.35 & \\bfseries 0.25 & \\bfseries 0.95 & 2.58 & \\bfseries 0.80 & \\bfseries 1.00 & \\bfseries 1.00 \\\\ \\hline\n",
      "random-choice & 1.49 & 0.71 & 0.50 & 3.58 & 1.41 & \\bfseries 1.00 & 0.90 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas dataframe to latex table\n",
    "def pandas_to_latex(df: pd.DataFrame, keep_formatting: bool = True) -> str:\n",
    "    \"\"\"Converts a pandas dataframe to a latex table.\n",
    "    Args:\n",
    "        df: The dataframe to convert.\n",
    "        keep_formatting: Whether to keep the formatting of the dataframe.\n",
    "    Returns:\n",
    "        The latex table as a string.\n",
    "    \"\"\"\n",
    "    latex = df.to_latex()\n",
    "    # Replace \\font-weightbold with proper latexbf formatting\n",
    "    latex = latex.replace(r\"\\font-weightbold\", r\"\\bfseries\")\n",
    "    # Insert \\hline after each newline \n",
    "    latex = latex.replace(r\"\\\\\", r\"\\\\ \\hline\")\n",
    "    # Insert \\hline at the top after first newline \\n\n",
    "    latex = latex.replace(r\"rrr}\", r\"rrr} \\hline\")\n",
    "    # Replace undersores with dashes\n",
    "    latex = latex.replace(\"_\", \"-\")\n",
    "    # Insert bold line before ideal-point-eucli\n",
    "    latex = latex.replace(\"ideal-point-\", r\"\\bfseries ideal-point-\")\n",
    "    # Rename columns according to dictionary\n",
    "    shortnames = {\n",
    "        'proximity': 'prox',\n",
    "        'k-feasibility-3': 'feas-3',\n",
    "        'discriminative-power-9': 'discrpow-9',\n",
    "        'sparsity': 'spars',\n",
    "        'plausibility': 'plausib',\n",
    "        'coverage': 'cover',\n",
    "        'actionable': 'actionab',\n",
    "    }\n",
    "    uparrow = ['discrpow-9', 'actionab', 'cover']\n",
    "    for k, v in shortnames.items():\n",
    "        latex = latex.replace(f'{k} ', rf'{v} $\\uparrow$' if v in uparrow else rf'{v} $\\downarrow$')\n",
    "        \n",
    "    \n",
    "    \n",
    "    return latex\n",
    " \n",
    "    \n",
    "print(pandas_to_latex(res, keep_formatting=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
